{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 64148,
          "databundleVersionId": 7669720,
          "sourceType": "competition"
        },
        {
          "sourceId": 11384,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 6216
        }
      ],
      "dockerImageVersionId": 30664,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "GPC (Gemma Python Chat)",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DLesmes/GPC/blob/main/GPC_(Gemma_Python_Chat).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'data-assistants-with-gemma:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F64148%2F7669720%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240320%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240320T125036Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D748fa3189c96f42b25895a5bb945182d2a31e07bf1d49090783a816681be0fedf0912960ac338c1678bf74a5b9e9f82615a0dcc14f69d644cfbf90b20a9bfc763f97d52208cebaa2adb37f2b7ae914707ae7495383c75063346a2d66a8e93f56b77b35ed0b8c577cbc7e106d9c3cb2bde3d829e46cf23c7b86e81a1542a5ea61ee9babc7ccd85c965f5a1432538b8c0546e8bc6ce9cae777262d06632e7eb98dc35b90efd4bc5d582532666c26dec661160d0d8e5f4c1c4cc749bbe072e672647a53903ec1d19a9c6f4ff1d5b77ec136642a0c32cc503a5f1230a2c867ad773c0d4c440719d0475302a5c306a15b3c80a815d7ef42723de416d4bf7387d5a497,gemma/transformers/2b/2:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F6216%2F11384%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240320%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240320T125037Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6c067764b38bd978f1d22556c42aba91f2c7eda2061c612e17cd1e7f480508c6a52bcd401561e33b473e3eca4bc5a01fdb39f54dc8c68efd9751ac28e0f17a9c42e89f82f4c42a11a567e3a1606df8bdf84b2214efc42b0582dd5a157459e53c75ffa8b3065c9b2a0f128c3a28ff4f98a0d837dc2ef37e9617134cb33ccebca181a07b149f3a72f97f3c5ad03eb30cf34d9ade81c4a8caaa77435675619e74ae80c6af87d90b481117561c5232bb83a31548a3eb14113a35241594a6874cc00ab36e133ac51437debab2f5b92dda079625f8e48242af11f7b5da596e106fe6c1e13a8e8dddacc6af4cb3a0b57781e6c8e5eb5261b34fb66274bc71e9e39f4188'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "tX8ZZtOB6etL"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-03-20T12:44:05.08274Z",
          "iopub.execute_input": "2024-03-20T12:44:05.083051Z",
          "iopub.status.idle": "2024-03-20T12:44:05.091349Z",
          "shell.execute_reply.started": "2024-03-20T12:44:05.083025Z",
          "shell.execute_reply": "2024-03-20T12:44:05.090336Z"
        },
        "trusted": true,
        "id": "O2salstP6etO",
        "outputId": "ae42e359-9ee2-4a86-859a-cc14201c5095"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/gemma/transformers/2b/2/model.safetensors.index.json\n/kaggle/input/gemma/transformers/2b/2/gemma-2b.gguf\n/kaggle/input/gemma/transformers/2b/2/config.json\n/kaggle/input/gemma/transformers/2b/2/model-00001-of-00002.safetensors\n/kaggle/input/gemma/transformers/2b/2/model-00002-of-00002.safetensors\n/kaggle/input/gemma/transformers/2b/2/tokenizer.json\n/kaggle/input/gemma/transformers/2b/2/tokenizer_config.json\n/kaggle/input/gemma/transformers/2b/2/special_tokens_map.json\n/kaggle/input/gemma/transformers/2b/2/.gitattributes\n/kaggle/input/gemma/transformers/2b/2/tokenizer.model\n/kaggle/input/gemma/transformers/2b/2/generation_config.json\n/kaggle/input/data-assistants-with-gemma/submission_categories.txt\n/kaggle/input/data-assistants-with-gemma/submission_instructions.txt\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCP 🤖 Gemma Python Chatbot"
      ],
      "metadata": {
        "id": "m4Mj0b0S6etP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.ibb.co/8xZNc32/Gemma.png)"
      ],
      "metadata": {
        "id": "mKp_VPEZ6etQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Gemma Python Chatbot 🚀🚀 help you to answer common questions about the 🐍 Python programming language, powereg by [Gemma 7B IT](https://blog.google/technology/developers/gemma-open-models/) updated with the latest"
      ],
      "metadata": {
        "id": "BeFSN09G6etQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain langchain-google-vertexai"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T04:27:41.455404Z",
          "iopub.execute_input": "2024-03-19T04:27:41.455976Z",
          "iopub.status.idle": "2024-03-19T04:28:49.351498Z",
          "shell.execute_reply.started": "2024-03-19T04:27:41.455945Z",
          "shell.execute_reply": "2024-03-19T04:28:49.350568Z"
        },
        "trusted": true,
        "id": "kxn_Bgn36etQ",
        "outputId": "66f3babb-e26a-4d94-e9ec-bd48e9f81871"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting langchain\n  Downloading langchain-0.1.12-py3-none-any.whl.metadata (13 kB)\nCollecting langchain-google-vertexai\n  Downloading langchain_google_vertexai-0.1.1-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\nCollecting langchain-community<0.1,>=0.0.28 (from langchain)\n  Downloading langchain_community-0.0.28-py3-none-any.whl.metadata (8.3 kB)\nCollecting langchain-core<0.2.0,>=0.1.31 (from langchain)\n  Downloading langchain_core-0.1.32-py3-none-any.whl.metadata (6.0 kB)\nCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.29-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nCollecting google-cloud-aiplatform<2.0.0,>=1.44.0 (from langchain-google-vertexai)\n  Downloading google_cloud_aiplatform-1.44.0-py2.py3-none-any.whl.metadata (27 kB)\nCollecting google-cloud-storage<3.0.0,>=2.14.0 (from langchain-google-vertexai)\n  Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl.metadata (6.1 kB)\nCollecting types-protobuf<5.0.0.0,>=4.24.0.4 (from langchain-google-vertexai)\n  Downloading types_protobuf-4.24.0.20240311-py3-none-any.whl.metadata (1.9 kB)\nCollecting types-requests<3.0.0,>=2.31.0 (from langchain-google-vertexai)\n  Downloading types_requests-2.31.0.20240311-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (2.11.1)\nRequirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (2.26.1)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.23.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (3.20.3)\nRequirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (21.3)\nRequirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (2.34.4)\nRequirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.11.0)\nRequirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.8.5.post1)\nCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai)\n  Downloading google_api_core-2.17.1-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.4.1)\nRequirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.7.0)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (1.5.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nRequirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (4.2.0)\nCollecting packaging>=14.3 (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nCollecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.2.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.62.0)\nINFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.51.1)\nRequirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.48.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (4.9)\nINFO: pip is looking at multiple versions of google-cloud-bigquery to determine which version is compatible with other requirements. This could take a while.\nCollecting google-cloud-bigquery<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai)\n  Downloading google_cloud_bigquery-3.19.0-py2.py3-none-any.whl.metadata (8.9 kB)\nRequirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (2.8.2)\nRequirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (0.12.7)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (0.5.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.16.0)\nDownloading langchain-0.1.12-py3-none-any.whl (809 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_google_vertexai-0.1.1-py3-none-any.whl (48 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_cloud_aiplatform-1.44.0-py2.py3-none-any.whl (4.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.1.32-py3-none-any.whl (260 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\nDownloading langsmith-0.1.29-py3-none-any.whl (70 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.9/70.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading types_protobuf-4.24.0.20240311-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading types_requests-2.31.0.20240311-py3-none-any.whl (14 kB)\nDownloading google_api_core-2.17.1-py3-none-any.whl (137 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_cloud_bigquery-3.19.0-py2.py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: urllib3, types-protobuf, packaging, orjson, types-requests, langsmith, google-api-core, langchain-core, langchain-text-splitters, langchain-community, google-cloud-storage, google-cloud-bigquery, langchain, google-cloud-aiplatform, langchain-google-vertexai\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.18\n    Uninstalling urllib3-1.26.18:\n      Successfully uninstalled urllib3-1.26.18\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n  Attempting uninstall: google-api-core\n    Found existing installation: google-api-core 2.11.1\n    Uninstalling google-api-core-2.11.1:\n      Successfully uninstalled google-api-core-2.11.1\n  Attempting uninstall: google-cloud-storage\n    Found existing installation: google-cloud-storage 1.44.0\n    Uninstalling google-cloud-storage-1.44.0:\n      Successfully uninstalled google-cloud-storage-1.44.0\n  Attempting uninstall: google-cloud-bigquery\n    Found existing installation: google-cloud-bigquery 2.34.4\n    Uninstalling google-cloud-bigquery-2.34.4:\n      Successfully uninstalled google-cloud-bigquery-2.34.4\n  Attempting uninstall: google-cloud-aiplatform\n    Found existing installation: google-cloud-aiplatform 0.6.0a1\n    Uninstalling google-cloud-aiplatform-0.6.0a1:\n      Successfully uninstalled google-cloud-aiplatform-0.6.0a1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.8.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.2 which is incompatible.\nbotocore 1.34.34 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.2.1 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2024.2.0 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.17.1 which is incompatible.\ngoogle-cloud-pubsub 2.19.0 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\njupyterlab 4.1.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed google-api-core-2.17.1 google-cloud-aiplatform-1.44.0 google-cloud-bigquery-3.19.0 google-cloud-storage-2.16.0 langchain-0.1.12 langchain-community-0.0.28 langchain-core-0.1.32 langchain-google-vertexai-0.1.1 langchain-text-splitters-0.0.1 langsmith-0.1.29 orjson-3.9.15 packaging-23.2 types-protobuf-4.24.0.20240311 types-requests-2.31.0.20240311 urllib3-2.1.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import GemmaChatLocalHF, GemmaLocalHF\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "access_token_read = UserSecretsClient().get_secret(\"HUGGINGFACE_TOKEN\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T04:28:49.352828Z",
          "iopub.execute_input": "2024-03-19T04:28:49.353108Z",
          "iopub.status.idle": "2024-03-19T04:29:02.599954Z",
          "shell.execute_reply.started": "2024-03-19T04:28:49.353083Z",
          "shell.execute_reply": "2024-03-19T04:29:02.599177Z"
        },
        "trusted": true,
        "id": "U9yVf2X-6etQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_access_token = access_token_read\n",
        "model_name: str = \"google/gemma-2b\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T04:29:02.601759Z",
          "iopub.execute_input": "2024-03-19T04:29:02.602209Z",
          "iopub.status.idle": "2024-03-19T04:29:02.606246Z",
          "shell.execute_reply.started": "2024-03-19T04:29:02.602183Z",
          "shell.execute_reply": "2024-03-19T04:29:02.60538Z"
        },
        "trusted": true,
        "id": "_HMvfILq6etR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GemmaLocalHF(model_name=\"google/gemma-2b\", hf_access_token=hf_access_token)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T04:29:02.60755Z",
          "iopub.execute_input": "2024-03-19T04:29:02.607934Z",
          "iopub.status.idle": "2024-03-19T04:29:43.902036Z",
          "shell.execute_reply.started": "2024-03-19T04:29:02.607901Z",
          "shell.execute_reply": "2024-03-19T04:29:43.901105Z"
        },
        "trusted": true,
        "id": "_XtXaYmo6etR",
        "outputId": "abf3783c-94af-4135-fd7d-b00d1f12211d",
        "colab": {
          "referenced_widgets": [
            "dfa9b5360ca343ee89165abf5e4fb28e",
            "6adcd67acfc543f49aa85f1b5486e47a",
            "388cd707e45a46639b1293d707cb9fce",
            "07b600a9868744c7b8b1165a5a3eaf2a",
            "63122483e012490489d9d25fb6389c01",
            "04c16fe3209f459cba1693165283ca93",
            "cd5d002919624ab8ac9359e40b09bbc1",
            "2338d26bbd1241b4bfdf625eb37a4467",
            "e14059ec8d0340ec9e8f76e1cf2dc942",
            "010fcdfa0ecd451b9e0b1036e4b68a35",
            "ed152dddf0634b05882b548fd5e976c4"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfa9b5360ca343ee89165abf5e4fb28e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6adcd67acfc543f49aa85f1b5486e47a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "388cd707e45a46639b1293d707cb9fce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/555 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07b600a9868744c7b8b1165a5a3eaf2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63122483e012490489d9d25fb6389c01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04c16fe3209f459cba1693165283ca93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd5d002919624ab8ac9359e40b09bbc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2338d26bbd1241b4bfdf625eb37a4467"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e14059ec8d0340ec9e8f76e1cf2dc942"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "010fcdfa0ecd451b9e0b1036e4b68a35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed152dddf0634b05882b548fd5e976c4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.invoke(\"what is the time cut of training dataset of Gemma google models?\", max_tokens=200)\n",
        "print(output)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T16:38:42.411253Z",
          "iopub.execute_input": "2024-03-16T16:38:42.411581Z",
          "iopub.status.idle": "2024-03-16T16:41:32.871709Z",
          "shell.execute_reply.started": "2024-03-16T16:38:42.411555Z",
          "shell.execute_reply": "2024-03-16T16:41:32.87069Z"
        },
        "trusted": true,
        "id": "JxB-qYX46etR",
        "outputId": "e19712bb-a380-458f-9c29-7dd4a0720dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "what is the time cut of training dataset of Gemma google models?\n\nHi @sagar.sahu,\n\nThe training time of the models is dependent on the model and the dataset.\n\nFor example, the training time for the <code>bert-base-uncased</code> model is 10 minutes.\n\nThe training time for the <code>bert-base-cased</code> model is 10 minutes.\n\nThe training time for the <code>bert-base-multilingual-uncased</code> model is 10 minutes.\n\nThe training time for the <code>bert-base-multilingual-cased</code> model is 10 minutes.\n\nThe training time for the <code>bert-large-uncased</code> model is 10 minutes.\n\nThe training time for the <code>bert-large-cased</code> model is 10 minutes.\n\nThe training time for the <code>bert-large-multilingual-uncased</code> model is\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.invoke(\"What is the data cut-off date for the Gemma Google models training dataset?\", max_tokens=200)\n",
        "print(output)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-16T16:44:36.995379Z",
          "iopub.execute_input": "2024-03-16T16:44:36.996093Z",
          "iopub.status.idle": "2024-03-16T16:47:25.137815Z",
          "shell.execute_reply.started": "2024-03-16T16:44:36.996058Z",
          "shell.execute_reply": "2024-03-16T16:47:25.136891Z"
        },
        "trusted": true,
        "id": "GXhU56Fu6etR",
        "outputId": "9075baea-9f60-4f0b-dfe4-edf5de518d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "What is the data cut-off date for the Gemma Google models training dataset?\n\nThe data cut-off date for the Gemma Google models training dataset is <strong>2020-01-01</strong>.\n\nWhat is the data cut-off date for the Gemma Google models validation dataset?\n\nThe data cut-off date for the Gemma Google models validation dataset is <strong>2020-01-01</strong>.\n\nWhat is the data cut-off date for the Gemma Google models test dataset?\n\nThe data cut-off date for the Gemma Google models test dataset is <strong>2020-01-01</strong>.\n\nWhat is the data cut-off date for the Gemma Google models development dataset?\n\nThe data cut-off date for the Gemma Google models development dataset is <strong>2020-01-01</strong>.\n\nWhat is the data cut-off date for the Gemma Google models training dataset\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.invoke(\"What is the most pythn command used?\", max_tokens=200)\n",
        "print(output)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-19T04:29:43.903209Z",
          "iopub.execute_input": "2024-03-19T04:29:43.903555Z",
          "iopub.status.idle": "2024-03-19T04:32:43.493483Z",
          "shell.execute_reply.started": "2024-03-19T04:29:43.903523Z",
          "shell.execute_reply": "2024-03-19T04:32:43.492525Z"
        },
        "trusted": true,
        "id": "AWebEyDD6etS",
        "outputId": "f3d89ee4-da0a-4e2b-a187-b98ab9bf0bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "What is the most pythn command used?\n\nAnswer:\n\nStep 1/2\nFirst, we need to understand what a Python command is. In Python, a command is a piece of code that is executed by the interpreter to perform a specific task. Some common Python commands include: - import: This command is used to import modules or packages into the current Python session. - print: This command is used to display text or data on the screen. - input: This command is used to prompt the user for input. - range: This command is used to create a sequence of numbers. - list: This command is used to create a list of items. - dict: This command is used to create a dictionary of key-value pairs. - for: This command is used to iterate over a sequence of items. - while: This command is used to execute a block of code repeatedly until a condition is met. - if: This command is used to execute a block of\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements"
      ],
      "metadata": {
        "id": "u2Xi7WIZ6etS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "c8j32Mod6etS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG"
      ],
      "metadata": {
        "id": "RyIBB_PV6etS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chatbot"
      ],
      "metadata": {
        "id": "sSOUbj3b6etS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCP - 0.0.1"
      ],
      "metadata": {
        "id": "zVCQ2mRa6etS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tunning"
      ],
      "metadata": {
        "id": "79BGnNeL6etS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCP - 0.1.0"
      ],
      "metadata": {
        "id": "tOut1pRb6etS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the environment\n",
        "!pip install --upgrade huggingface_hub\n",
        "from huggingface_hub import login\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "access_token_read = UserSecretsClient().get_secret(\"HUGGINGFACE_TOKEN\")\n",
        "login(token = access_token_read)\n",
        "#!pip install git+https://github.com/huggingface/transformers -U\n",
        "!pip install accelerate\n",
        "!pip install -i https://pypi.org/simple/ bitsandbytes\n",
        "#!pip install --upgrade transformers\n",
        "!pip install transformers==4.33.1\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from typing import *"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T12:44:05.093378Z",
          "iopub.execute_input": "2024-03-20T12:44:05.093672Z",
          "iopub.status.idle": "2024-03-20T12:45:09.906346Z",
          "shell.execute_reply.started": "2024-03-20T12:44:05.093648Z",
          "shell.execute_reply": "2024-03-20T12:45:09.905364Z"
        },
        "trusted": true,
        "id": "sctLsRPj6etS",
        "outputId": "53686009-4f2d-47d5-9375-2e5830c36c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.20.3)\nCollecting huggingface_hub\n  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\nDownloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface_hub\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.20.3\n    Uninstalling huggingface-hub-0.20.3:\n      Successfully uninstalled huggingface-hub-0.20.3\nSuccessfully installed huggingface_hub-0.21.4\nToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.27.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.21.4)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nLooking in indexes: https://pypi.org/simple/\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.0\nCollecting transformers==4.33.1\n  Downloading transformers-4.33.1-py3-none-any.whl.metadata (119 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (0.21.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (2.31.0)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.1)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.1) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.1) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.1) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.33.1) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.1) (2024.2.2)\nDownloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.38.1\n    Uninstalling transformers-4.38.1:\n      Successfully uninstalled transformers-4.38.1\nSuccessfully installed tokenizers-0.13.3 transformers-4.33.1\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"/kaggle/input/gemma/transformers/2b/2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_checkpoint, torch_dtype=torch.float16).cuda()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T12:45:17.854539Z",
          "iopub.execute_input": "2024-03-20T12:45:17.854945Z",
          "iopub.status.idle": "2024-03-20T12:45:19.778092Z",
          "shell.execute_reply.started": "2024-03-20T12:45:17.854901Z",
          "shell.execute_reply": "2024-03-20T12:45:19.776536Z"
        },
        "trusted": true,
        "id": "6D_3P6mN6etS",
        "outputId": "568d1de3-1d43-48c3-e03d-48bdfd4a1111"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Unexpected exception formatting exception. Falling back to standard exception\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1390, in _get_module\n  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1004, in _find_and_load_unlocked\nModuleNotFoundError: No module named 'transformers.models.gemma.configuration_gemma'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_34/682258503.py\", line 3, in <module>\n    model = AutoModelForCausalLM.from_pretrained(model_checkpoint, torch_dtype=torch.float16).cuda()\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 521, in from_pretrained\n    if kwargs.get(\"torch_dtype\", None) == \"auto\":\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\", line 1128, in from_pretrained\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\", line 830, in __getitem__\n    ALL_PRETRAINED_CONFIG_ARCHIVE_MAP = _LazyLoadAllMappings(CONFIG_ARCHIVE_MAP_MAPPING_NAMES)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1380, in __getattr__\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1392, in _get_module\nRuntimeError: Failed to import transformers.models.gemma.configuration_gemma because of the following error (look up to see its traceback):\nNo module named 'transformers.models.gemma.configuration_gemma'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n    stb = self.InteractiveTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n    return FormattedTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n    return VerboseTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n    frames.append(self.format_record(record))\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n    frame_info.lines, Colors, self.has_colors, lvals\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n    return self._sd.lines\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n    pieces = self.included_pieces\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n    pos = scope_pieces.index(self.executing_piece)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n    return only(\n  File \"/opt/conda/lib/python3.10/site-packages/executing/executing.py\", line 116, in only\n    raise NotOneValueFound('Expected one value, found 0')\nexecuting.executing.NotOneValueFound: Expected one value, found 0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pkg_resources\n",
        "installed_packages = pkg_resources.working_set\n",
        "installed_packages_list = sorted([\"%s==%s\" % (i.key, i.version) for i in installed_packages])\n",
        "for m in installed_packages_list:\n",
        "    print(m)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T12:48:52.376371Z",
          "iopub.execute_input": "2024-03-20T12:48:52.377254Z",
          "iopub.status.idle": "2024-03-20T12:48:52.694662Z",
          "shell.execute_reply.started": "2024-03-20T12:48:52.377213Z",
          "shell.execute_reply": "2024-03-20T12:48:52.69371Z"
        },
        "trusted": true,
        "id": "1CLfAz-Z6etS",
        "outputId": "81f74c61-3066-43d2-c7d9-80c75110e013"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_34/2312216702.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n  import pkg_resources\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "absl-py==1.4.0\naccelerate==0.27.2\naccess==1.1.9\naffine==2.4.0\naiobotocore==2.11.2\naiofiles==22.1.0\naiohttp-cors==0.7.0\naiohttp==3.9.1\naioitertools==0.11.0\naiorwlock==1.3.0\naiosignal==1.3.1\naiosqlite==0.19.0\nalbumentations==1.4.0\nalembic==1.13.1\naltair==5.2.0\nannotated-types==0.6.0\nannoy==1.17.3\nanyio==4.2.0\napache-beam==2.46.0\naplus==0.11.0\nappdirs==1.4.4\narchspec==0.2.2\nargon2-cffi-bindings==21.2.0\nargon2-cffi==23.1.0\narray-record==0.5.0\narrow==1.3.0\narviz==0.17.0\nastroid==3.0.3\nastropy-iers-data==0.2024.2.19.0.28.47\nastropy==6.0.0\nasttokens==2.4.1\nastunparse==1.6.3\nasync-lru==2.0.4\nasync-timeout==4.0.3\nattrs==23.2.0\naudioread==3.0.1\nautopep8==2.0.4\nbabel==2.14.0\nbackoff==2.2.1\nbayesian-optimization==1.4.3\nbayespy==0.5.28\nbeatrix-jupyterlab==2023.128.151533\nbeautifulsoup4==4.12.2\nbidict==0.23.1\nbiopython==1.83\nbitsandbytes==0.43.0\nblake3==0.2.1\nbleach==6.1.0\nblessed==1.20.0\nblinker==1.7.0\nblis==0.7.10\nblosc2==2.5.1\nbokeh==3.3.4\nboltons==23.1.1\nboruta==0.3\nboto3==1.26.100\nbotocore==1.34.34\nbq-helper==0.4.1\nbqplot==0.12.43\nbranca==0.7.1\nbrewer2mpl==1.4.1\nbrotli==1.0.9\nbrotlipy==0.7.0\ncached-property==1.5.2\ncachetools==4.2.4\ncartopy==0.22.0\ncatalogue==2.0.10\ncatalyst==22.4\ncatboost==1.2.2\ncategory-encoders==2.6.3\ncertifi==2024.2.2\ncesium==0.12.1\ncffi==1.16.0\ncharset-normalizer==3.3.2\nchex==0.1.85\ncleverhans==4.0.0\nclick-plugins==1.1.1\nclick==8.1.7\ncligj==0.7.2\ncloud-tpu-client==0.10\ncloud-tpu-profiler==2.4.0\ncloudpathlib==0.16.0\ncloudpickle==2.2.1\ncmdstanpy==1.2.1\ncmudict==1.0.18\ncolorama==0.4.6\ncolorcet==3.0.1\ncolorful==0.5.6\ncolorlog==6.8.2\ncolorlover==0.3.0\ncomm==0.2.1\nconda-libmamba-solver==23.7.0\nconda-package-handling==2.2.0\nconda-package-streaming==0.9.0\nconda==23.7.4\nconfection==0.1.4\ncontextily==1.5.0\ncontourpy==1.2.0\nconvertdate==2.4.0\ncrcmod==1.7\ncryptography==41.0.7\ncuda-python==12.3.0\ncudf==23.8.0\ncufflinks==0.17.3\ncuml==23.8.0\ncupy==13.0.0\ncvxcanon==0.1.2\ncycler==0.12.1\ncymem==2.0.8\ncysignals==1.11.4\ncython==3.0.8\ncytoolz==0.12.3\ndaal4py==2024.1.0\ndaal==2024.1.0\ndacite==1.8.1\ndask-cuda==23.8.0\ndask-cudf==23.8.0\ndask==2024.2.0\ndataclasses-json==0.6.4\ndataproc-jupyter-plugin==0.1.66\ndatasets==2.1.0\ndatashader==0.16.0\ndatatile==1.0.3\ndb-dtypes==1.2.0\ndeap==1.4.1\ndebugpy==1.8.0\ndecorator==5.1.1\ndeepdiff==6.7.1\ndefusedxml==0.7.1\ndelorean==1.0.0\ndeprecated==1.2.14\ndeprecation==2.1.0\ndescartes==1.1.0\ndill==0.3.8\ndipy==1.8.0\ndistlib==0.3.8\ndistributed==2023.7.1\ndistro==1.9.0\ndm-tree==0.1.8\ndocker-pycreds==0.4.0\ndocker==7.0.0\ndocopt==0.6.2\ndocstring-parser==0.15\ndocstring-to-markdown==0.15\ndocutils==0.20.1\nearthengine-api==0.1.391\neasydict==1.12\neasyocr==1.7.1\necos==2.0.13\neli5==0.13.0\nemoji==2.10.1\nen-core-web-lg==3.7.1\nen-core-web-sm==3.7.1\nentrypoints==0.4\nephem==4.1.5\nesda==2.5.1\nessentia==2.1b6.dev1110\net-xmlfile==1.1.0\netils==1.6.0\nexceptiongroup==1.2.0\nexecuting==2.0.1\nexplainable-ai-sdk==1.3.3\nfarama-notifications==0.0.4\nfastai==2.7.14\nfastapi==0.108.0\nfastavro==1.9.3\nfastcore==1.5.29\nfastdownload==0.0.7\nfasteners==0.19\nfastjsonschema==2.19.1\nfastprogress==1.0.3\nfastrlock==0.8.2\nfasttext==0.9.2\nfbpca==1.0\nfeather-format==0.4.1\nfeaturetools==1.29.0\nfilelock==3.13.1\nfiona==1.9.5\nfitter==1.7.0\nflake8==7.0.0\nflashtext==2.7\nflask==3.0.2\nflatbuffers==23.5.26\nflax==0.8.1\nfolium==0.15.1\nfonttools==4.47.0\nfqdn==1.5.1\nfrozendict==2.4.0\nfrozenlist==1.4.1\nfsspec==2024.2.0\nfuncy==2.0\nfury==0.9.0\nfuture==1.0.0\nfuzzywuzzy==0.18.0\ngast==0.5.4\ngatspy==0.3\ngcsfs==2023.12.2.post1\ngensim==4.3.2\ngeographiclib==2.0\ngeohash==1.0\ngeojson==3.1.0\ngeopandas==0.14.3\ngeoplot==0.5.1\ngeopy==2.4.1\ngeoviews==1.11.1\nggplot==0.11.5\ngiddy==2.3.5\ngitdb==4.0.11\ngitpython==3.1.41\ngoogle-ai-generativelanguage==0.4.0\ngoogle-api-core==2.11.1\ngoogle-api-python-client==2.118.0\ngoogle-apitools==0.5.31\ngoogle-auth-httplib2==0.1.1\ngoogle-auth-oauthlib==1.2.0\ngoogle-auth==2.26.1\ngoogle-cloud-aiplatform==0.6.0a1\ngoogle-cloud-artifact-registry==1.10.0\ngoogle-cloud-automl==1.0.1\ngoogle-cloud-bigquery==2.34.4\ngoogle-cloud-bigtable==1.7.3\ngoogle-cloud-core==2.4.1\ngoogle-cloud-datastore==2.19.0\ngoogle-cloud-dlp==3.14.0\ngoogle-cloud-jupyter-config==0.0.5\ngoogle-cloud-language==2.13.1\ngoogle-cloud-monitoring==2.18.0\ngoogle-cloud-pubsub==2.19.0\ngoogle-cloud-pubsublite==1.9.0\ngoogle-cloud-recommendations-ai==0.7.1\ngoogle-cloud-resource-manager==1.11.0\ngoogle-cloud-spanner==3.40.1\ngoogle-cloud-storage==1.44.0\ngoogle-cloud-translate==3.12.1\ngoogle-cloud-videointelligence==2.13.1\ngoogle-cloud-vision==2.8.0\ngoogle-crc32c==1.5.0\ngoogle-generativeai==0.3.2\ngoogle-pasta==0.2.0\ngoogle-resumable-media==2.7.0\ngoogleapis-common-protos==1.62.0\ngplearn==0.4.2\ngpustat==1.0.0\ngpxpy==1.6.2\ngraphviz==0.20.1\ngreenlet==3.0.3\ngrpc-google-iam-v1==0.12.7\ngrpcio-status==1.48.1\ngrpcio==1.51.1\ngviz-api==1.10.0\ngym-notices==0.0.8\ngym==0.26.2\ngymnasium==0.29.0\nh11==0.14.0\nh2o==3.44.0.3\nh5netcdf==1.3.0\nh5py==3.10.0\nhaversine==2.8.1\nhdfs==2.7.3\nhep-ml==0.7.2\nhijri-converter==2.3.1\nhmmlearn==0.3.0\nholidays==0.24\nholoviews==1.18.3\nhpsklearn==0.1.0\nhtml5lib==1.1\nhtmlmin==0.1.12\nhttpcore==1.0.4\nhttplib2==0.21.0\nhttptools==0.6.1\nhttpx==0.27.0\nhuggingface-hub==0.21.4\nhumanize==4.9.0\nhunspell==0.5.5\nhusl==4.0.3\nhydra-slayer==0.5.0\nhyperopt==0.2.7\nhypertools==0.8.0\nidna==3.6\nigraph==0.11.4\nimagecodecs==2024.1.1\nimagehash==4.3.1\nimageio==2.33.1\nimbalanced-learn==0.12.0\nimgaug==0.4.0\nimportlib-metadata==6.11.0\nimportlib-resources==6.1.1\ninequality==1.0.1\niniconfig==2.0.0\nipydatawidgets==4.3.5\nipykernel==6.28.0\nipyleaflet==0.18.2\nipympl==0.7.0\nipython-genutils==0.2.0\nipython-sql==0.5.0\nipython==8.20.0\nipyvolume==0.6.3\nipyvue==1.10.1\nipyvuetify==1.8.10\nipywebrtc==0.6.0\nipywidgets==7.7.1\nisoduration==20.11.0\nisort==5.13.2\nisoweek==1.3.3\nitsdangerous==2.1.2\njanome==0.5.0\njaraco.classes==3.3.0\njax-jumpy==1.0.0\njax==0.4.23\njaxlib==0.4.23.dev20240116\njedi==0.19.1\njeepney==0.8.0\njieba==0.42.1\njinja2==3.1.2\njmespath==1.0.1\njoblib==1.3.2\njson5==0.9.14\njsonpatch==1.33\njsonpointer==2.4\njsonschema-specifications==2023.12.1\njsonschema==4.20.0\njupyter-client==7.4.9\njupyter-console==6.6.3\njupyter-core==5.7.1\njupyter-events==0.9.0\njupyter-http-over-ws==0.0.8\njupyter-lsp==1.5.1\njupyter-server-fileid==0.9.1\njupyter-server-mathjax==0.2.6\njupyter-server-proxy==4.1.0\njupyter-server-terminals==0.5.1\njupyter-server-ydoc==0.8.0\njupyter-server==2.12.5\njupyter-ydoc==0.2.5\njupyterlab-git==0.44.0\njupyterlab-lsp==5.0.3\njupyterlab-pygments==0.3.0\njupyterlab-server==2.25.2\njupyterlab-widgets==3.0.9\njupyterlab==4.1.2\njupytext==1.16.0\nkaggle-environments==1.14.3\nkaggle==1.6.6\nkagglehub==0.1.9\nkeras-cv==0.8.2\nkeras-nlp==0.8.1\nkeras-tuner==1.4.6\nkeras==3.0.5\nkernels-mixer==0.0.7\nkeyring==24.3.0\nkeyrings.google-artifactregistry-auth==1.1.2\nkfp-pipeline-spec==0.2.2\nkfp-server-api==2.0.5\nkfp==2.5.0\nkiwisolver==1.4.5\nkmapper==2.0.1\nkmodes==0.12.2\nkorean-lunar-calendar==0.3.1\nkornia==0.7.1\nkt-legacy==1.0.5\nkubernetes==26.1.0\nlangcodes==3.3.0\nlangid==1.1.6\nlazy-loader==0.3\nlearntools==0.3.4\nleven==1.0.4\nlevenshtein==0.25.0\nlibclang==16.0.6\nlibmambapy==1.5.0\nlibpysal==4.9.2\nlibrosa==0.10.1\nlightgbm==4.2.0\nlightning-utilities==0.10.1\nlime==0.2.0.1\nline-profiler==4.1.2\nlinkify-it-py==2.0.3\nllvmlite==0.41.1\nlml==0.1.0\nlocket==1.0.0\nloguru==0.7.2\nlunarcalendar==0.0.9\nlxml==5.1.0\nlz4==4.3.3\nmako==1.3.2\nmamba==1.5.0\nmapclassify==2.6.1\nmarisa-trie==1.1.0\nmarkdown-it-py==3.0.0\nmarkdown==3.5.2\nmarkovify==0.9.4\nmarkupsafe==2.1.3\nmarshmallow==3.20.2\nmatplotlib-inline==0.1.6\nmatplotlib-venn==0.11.10\nmatplotlib==3.7.5\nmccabe==0.7.0\nmdit-py-plugins==0.4.0\nmdurl==0.1.2\nmemory-profiler==0.61.0\nmenuinst==2.0.1\nmercantile==1.2.1\nmgwr==2.2.1\nmissingno==0.5.2\nmistune==0.8.4\nmizani==0.11.0\nml-dtypes==0.2.0\nmlcrate==0.2.0\nmlens==0.2.3\nmlxtend==0.23.1\nmmh3==4.1.0\nmne==1.6.1\nmnist==0.2.2\nmock==5.1.0\nmomepy==0.7.0\nmore-itertools==10.2.0\nmpld3==0.5.10\nmpmath==1.3.0\nmsgpack-numpy==0.4.8\nmsgpack==1.0.7\nmultidict==6.0.4\nmultimethod==1.10\nmultipledispatch==1.0.0\nmultiprocess==0.70.16\nmunkres==1.1.4\nmurmurhash==1.0.10\nmypy-extensions==1.0.0\nnamex==0.0.7\nnb-conda-kernels==2.3.1\nnb-conda==2.2.1\nnbclassic==1.0.0\nnbclient==0.5.13\nnbconvert==6.4.5\nnbdime==3.2.0\nnbformat==5.9.2\nndindex==1.8\nnest-asyncio==1.5.8\nnetworkx==3.2.1\nnibabel==5.2.0\nnilearn==0.10.3\nninja==1.11.1.1\nnltk==3.2.4\nnose==1.3.7\nnotebook-executor==0.2\nnotebook-shim==0.2.3\nnotebook==6.5.4\nnumba==0.58.1\nnumexpr==2.9.0\nnumpy==1.26.4\nnvidia-ml-py==11.495.46\nnvtx==0.2.10\noauth2client==4.1.3\noauthlib==3.2.2\nobjsize==0.6.1\nodfpy==1.4.1\nolefile==0.47\nonnx==1.15.0\nopencensus-context==0.1.3\nopencensus==0.11.4\nopencv-contrib-python==4.9.0.80\nopencv-python-headless==4.9.0.80\nopencv-python==4.9.0.80\nopenpyxl==3.1.2\nopenslide-python==1.3.1\nopentelemetry-api==1.22.0\nopentelemetry-exporter-otlp-proto-common==1.22.0\nopentelemetry-exporter-otlp-proto-grpc==1.22.0\nopentelemetry-exporter-otlp-proto-http==1.22.0\nopentelemetry-exporter-otlp==1.22.0\nopentelemetry-proto==1.22.0\nopentelemetry-sdk==1.22.0\nopentelemetry-semantic-conventions==0.43b0\nopt-einsum==3.3.0\noptax==0.1.9\noptuna==3.5.0\norbax-checkpoint==0.5.3\nordered-set==4.1.0\norderedmultidict==1.0.1\norjson==3.9.10\nortools==9.4.1874\nosmnx==1.9.1\noverrides==7.4.0\npackaging==21.3\npandas-datareader==0.10.0\npandas-profiling==3.6.6\npandas-summary==0.2.0\npandas==2.1.4\npandasql==0.7.3\npandocfilters==1.5.0\npanel==1.3.8\npapermill==2.5.0\nparam==2.0.2\nparso==0.8.3\npartd==1.4.1\npath.py==12.5.0\npath==16.10.0\npathos==0.3.2\npathy==0.10.3\npatsy==0.5.6\npdf2image==1.17.0\npettingzoo==1.24.0\npexpect==4.8.0\nphik==0.12.4\npickleshare==0.7.5\npillow==9.5.0\npip==23.3.2\npkgutil-resolve-name==1.3.10\nplatformdirs==4.2.0\nplotly-express==0.4.1\nplotly==5.18.0\nplotnine==0.13.0\npluggy==1.3.0\npointpats==2.4.0\npolars==0.20.10\npolyglot==16.7.4\npooch==1.8.1\npox==0.3.4\nppca==0.0.4\nppft==1.7.6.8\npreprocessing==0.1.13\npreshed==3.0.9\nprettytable==3.9.0\nprogressbar2==4.3.2\nprometheus-client==0.19.0\npromise==2.3\nprompt-toolkit==3.0.42\npronouncing==0.2.0\nprophet==1.1.1\nproto-plus==1.23.0\nprotobuf==3.20.3\npsutil==5.9.3\nptyprocess==0.7.0\npudb==2024.1\npulp==2.8.0\npure-eval==0.2.2\npy-cpuinfo==9.0.0\npy-spy==0.3.14\npy4j==0.10.9.7\npyaml==23.12.0\npyarabic==0.6.15\npyarrow==11.0.0\npyasn1-modules==0.3.0\npyasn1==0.5.1\npyastronomy==0.20.0\npybind11==2.11.1\npyclipper==1.3.0.post5\npycodestyle==2.11.1\npycosat==0.6.6\npycparser==2.21\npycryptodome==3.20.0\npyct==0.5.0\npycuda==2024.1\npydantic-core==2.14.6\npydantic==2.5.3\npydegensac==0.1.2\npydicom==2.4.4\npydocstyle==6.3.0\npydot==1.4.2\npydub==0.25.1\npyemd==1.0.0\npyerfa==2.0.1.1\npyexcel-io==0.6.6\npyexcel-ods==0.6.0\npyfasttext==0.4.6\npyflakes==3.2.0\npygltflib==1.16.1\npygments==2.17.2\npyjwt==2.8.0\npykalman==0.9.5\npyldavis==3.4.1\npylibraft==23.8.0\npylint==3.0.3\npymc3==3.11.4\npymeeus==0.5.12\npymongo==3.13.0\npympler==1.0.1\npynndescent==0.5.11\npynvml==11.4.1\npynvrtc==9.2\npyocr==0.8.5\npyopenssl==23.3.0\npyparsing==3.1.1\npypdf==4.0.2\npyproj==3.6.1\npysal==24.1\npyshp==2.3.1\npysocks==1.7.1\npytesseract==0.3.10\npytest==8.0.1\npython-bidi==0.4.2\npython-dateutil==2.8.2\npython-dotenv==1.0.0\npython-json-logger==2.0.7\npython-levenshtein==0.25.0\npython-louvain==0.16\npython-lsp-jsonrpc==1.1.2\npython-lsp-server==1.10.0\npython-slugify==8.0.4\npython-utils==3.8.2\npythreejs==2.4.2\npytoolconfig==1.3.1\npytools==2023.1.1\npytorch-ignite==0.4.13\npytorch-lightning==2.2.0.post0\npytz==2023.3.post1\npyu2f==0.1.5\npyupset==0.1.1.post7\npyviz-comms==3.0.1\npywavelets==1.5.0\npyyaml==6.0.1\npyzmq==24.0.1\nqgrid==1.3.1\nqtconsole==5.5.1\nqtpy==2.4.1\nquantecon==0.7.1\nquantities==0.15.0\nqudida==0.0.4\nraft-dask==23.8.0\nrapidfuzz==3.6.1\nrasterio==1.3.9\nrasterstats==0.19.0\nray-cpp==2.9.0\nray==2.9.0\nreferencing==0.32.1\nregex==2023.12.25\nrequests-oauthlib==1.3.1\nrequests-toolbelt==0.10.1\nrequests==2.31.0\nresponses==0.18.0\nretrying==1.3.3\nrfc3339-validator==0.1.4\nrfc3986-validator==0.1.1\nrgf-python==3.12.0\nrich-click==1.7.3\nrich==13.7.0\nrmm==23.8.0\nrope==1.12.0\nrpds-py==0.16.2\nrsa==4.9\nrtree==1.2.0\nruamel-yaml-conda==0.15.100\nruamel.yaml.clib==0.2.7\nruamel.yaml==0.17.40\ns2sphere==0.2.5\ns3fs==2024.2.0\ns3transfer==0.6.2\nsafetensors==0.4.2\nscattertext==0.1.19\nscikit-image==0.22.0\nscikit-learn-intelex==2024.1.0\nscikit-learn==1.2.2\nscikit-multilearn==0.2.0\nscikit-optimize==0.9.0\nscikit-plot==0.3.7\nscikit-surprise==1.1.3\nscipy==1.11.4\nseaborn==0.12.2\nsecretstorage==3.3.3\nsegment-anything==1.0\nsegregation==2.5\nsemver==3.0.2\nsend2trash==1.8.2\nsentencepiece==0.2.0\nsentry-sdk==1.40.5\nsetproctitle==1.3.3\nsetuptools-git==1.2\nsetuptools-scm==8.0.4\nsetuptools==69.0.3\nshap==0.44.1\nshapely==1.8.5.post1\nshellingham==1.5.4\nshimmy==1.3.0\nsimpervisor==1.0.0\nsimpleitk==2.3.1\nsimplejson==3.19.2\nsix==1.16.0\nsklearn-pandas==2.2.0\nslicer==0.0.7\nsmart-open==6.4.0\nsmhasher==0.150.1\nsmmap==5.0.1\nsniffio==1.3.0\nsnowballstemmer==2.2.0\nsnuggs==1.4.7\nsortedcontainers==2.4.0\nsoundfile==0.12.1\nsoupsieve==2.5\nsoxr==0.3.7\nspacy-legacy==3.0.12\nspacy-loggers==1.0.5\nspacy==3.7.2\nspaghetti==1.7.5.post1\nspectral==0.23.1\nspglm==1.1.0\nsphinx-rtd-theme==0.2.4\nspint==1.0.7\nsplot==1.1.5.post1\nspopt==0.6.0\nspreg==1.4.2\nspvcm==0.3.0\nsqlalchemy==2.0.25\nsqlparse==0.4.4\nsquarify==0.4.3\nsrsly==2.4.8\nstable-baselines3==2.1.0\nstack-data==0.6.2\nstanio==0.3.0\nstarlette==0.32.0.post1\nstatsmodels==0.14.1\nstemming==1.0.1\nstop-words==2018.7.23\nstopit==1.1.2\nstumpy==1.12.0\nsympy==1.12\ntables==3.9.2\ntabulate==0.9.0\ntangled-up-in-unicode==0.2.0\ntbb==2021.11.0\ntblib==3.0.0\ntenacity==8.2.3\ntensorboard-data-server==0.7.2\ntensorboard-plugin-profile==2.15.0\ntensorboard==2.15.1\ntensorboardx==2.6.2.2\ntensorflow-cloud==0.1.16\ntensorflow-datasets==4.9.4\ntensorflow-decision-forests==1.8.1\ntensorflow-estimator==2.15.0\ntensorflow-hub==0.16.1\ntensorflow-io-gcs-filesystem==0.35.0\ntensorflow-io==0.35.0\ntensorflow-metadata==0.14.0\ntensorflow-probability==0.23.0\ntensorflow-serving-api==2.14.1\ntensorflow-text==2.15.0\ntensorflow-transform==0.14.0\ntensorflow==2.15.0\ntensorpack==0.11\ntensorstore==0.1.53\ntermcolor==2.4.0\nterminado==0.18.0\ntestpath==0.6.0\ntext-unidecode==1.3\ntextblob==0.18.0.post0\ntexttable==1.7.0\ntf-keras==2.15.0\ntfp-nightly==0.24.0.dev0\ntheano-pymc==1.1.2\ntheano==1.0.5\nthinc==8.2.2\nthreadpoolctl==3.2.0\ntifffile==2023.12.9\ntimm==0.9.16\ntinycss2==1.2.1\ntobler==0.11.2\ntokenizers==0.13.3\ntoml==0.10.2\ntomli==2.0.1\ntomlkit==0.12.3\ntoolz==0.12.1\ntorch==2.1.2\ntorchaudio==2.1.2\ntorchdata==0.7.1\ntorchinfo==1.8.0\ntorchmetrics==1.3.1\ntorchtext==0.16.2\ntorchvision==0.16.2\ntornado==6.3.3\ntpot==0.12.1\ntqdm==4.66.1\ntraceml==1.0.8\ntraitlets==5.9.0\ntraittypes==0.2.1\ntransformers==4.33.1\ntreelite-runtime==3.2.0\ntreelite==3.2.0\ntrueskill==0.4.5\ntruststore==0.8.0\ntrx-python==0.2.9\ntsfresh==0.20.2\ntypeguard==4.1.5\ntyper==0.9.0\ntypes-python-dateutil==2.8.19.20240106\ntyping-extensions==4.9.0\ntyping-inspect==0.9.0\ntyping-utils==0.1.0\ntzdata==2023.4\ntzlocal==5.2\nuc-micro-py==1.0.3\nucx-py==0.33.0\nujson==5.9.0\numap-learn==0.5.5\nunicodedata2==15.1.0\nunidecode==1.3.8\nupdate-checker==0.18.0\nuri-template==1.3.0\nuritemplate==3.0.1\nurllib3==1.26.18\nurwid-readline==0.13\nurwid==2.6.4\nuvicorn==0.25.0\nuvloop==0.19.0\nvaex-astro==0.9.3\nvaex-core==4.17.1\nvaex-hdf5==0.14.1\nvaex-jupyter==0.8.2\nvaex-ml==0.18.3\nvaex-server==0.9.0\nvaex-viz==0.5.4\nvaex==4.17.0\nvec-noise==1.1.4\nvecstack==0.4.0\nvirtualenv==20.21.0\nvisions==0.7.5\nvowpalwabbit==9.9.0\nvtk==9.3.0\nwand==0.6.13\nwandb==0.16.3\nwasabi==1.1.2\nwatchfiles==0.21.0\nwavio==0.0.8\nwcwidth==0.2.13\nweasel==0.3.4\nwebcolors==1.13\nwebencodings==0.5.1\nwebsocket-client==1.7.0\nwebsockets==12.0\nwerkzeug==3.0.1\nwfdb==4.1.2\nwhatthepatch==1.0.5\nwheel==0.42.0\nwidgetsnbextension==3.6.6\nwitwidget==1.8.1\nwoodwork==0.28.0\nwordcloud==1.9.3\nwordsegment==1.3.1\nwrapt==1.14.1\nxarray-einstats==0.7.0\nxarray==2024.2.0\nxgboost==2.0.3\nxvfbwrapper==0.2.9\nxxhash==3.4.1\nxyzservices==2023.10.1\ny-py==0.6.2\nyapf==0.40.2\nyarl==1.9.3\nydata-profiling==4.6.4\nyellowbrick==1.5\nypy-websocket==0.8.4\nzict==3.0.0\nzipp==3.17.0\nzstandard==0.22.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3P2j84a86etT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/gemma/transformers/2b/2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"/kaggle/input/gemma/transformers/2b/2\")\n",
        "# Use the model\n",
        "input_text = \"What is the best thing about Kaggle?\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\")\n",
        "outputs = model.generate(**input_ids)\n",
        "print(tokenizer.decode(outputs[0]))\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T12:03:55.565536Z",
          "iopub.execute_input": "2024-03-20T12:03:55.566347Z",
          "iopub.status.idle": "2024-03-20T12:03:56.535792Z",
          "shell.execute_reply.started": "2024-03-20T12:03:55.566315Z",
          "shell.execute_reply": "2024-03-20T12:03:56.534585Z"
        },
        "trusted": true,
        "id": "CCkkSTHK6etT",
        "outputId": "a8972e25-77bd-4f16-fdca-7b2d994aef5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Unexpected exception formatting exception. Falling back to standard exception\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1390, in _get_module\n    if \"torch\" in backends and \"tf\" not in backends and not is_torch_available() and is_tf_available():\n  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 37, in <module>\n    from ..utils import ModelOutput, is_accelerate_available, is_torchdynamo_compiling, logging\nImportError: cannot import name 'is_torchdynamo_compiling' from 'transformers.utils' (/opt/conda/lib/python3.10/site-packages/transformers/utils/__init__.py)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1390, in _get_module\n    if \"torch\" in backends and \"tf\" not in backends and not is_torch_available() and is_tf_available():\n  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py\", line 35, in <module>\n    from ...modeling_utils import PreTrainedModel\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 44, in <module>\n    from .generation import GenerationConfig, GenerationMixin\n  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1380, in __getattr__\n    )\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1392, in _get_module\nRuntimeError: Failed to import transformers.generation.utils because of the following error (look up to see its traceback):\ncannot import name 'is_torchdynamo_compiling' from 'transformers.utils' (/opt/conda/lib/python3.10/site-packages/transformers/utils/__init__.py)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_33/2340859303.py\", line 3, in <module>\n    model = AutoModelForCausalLM.from_pretrained(\"/kaggle/input/gemma/transformers/2b/2\")\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 560, in from_pretrained\n    )\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 381, in _get_model_class\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 732, in __getitem__\n    if model_type in self._model_mapping:\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 746, in _load_attr_from_module\n    if module_name not in self._modules:\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 690, in getattribute_from_module\n    if isinstance(attr, tuple):\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1380, in __getattr__\n    )\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1392, in _get_module\nRuntimeError: Failed to import transformers.models.gemma.modeling_gemma because of the following error (look up to see its traceback):\nFailed to import transformers.generation.utils because of the following error (look up to see its traceback):\ncannot import name 'is_torchdynamo_compiling' from 'transformers.utils' (/opt/conda/lib/python3.10/site-packages/transformers/utils/__init__.py)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n    stb = self.InteractiveTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n    return FormattedTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n    return VerboseTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n    frames.append(self.format_record(record))\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n    frame_info.lines, Colors, self.has_colors, lvals\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n    return self._sd.lines\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n    pieces = self.included_pieces\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n    pos = scope_pieces.index(self.executing_piece)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n    return only(\n  File \"/opt/conda/lib/python3.10/site-packages/executing/executing.py\", line 116, in only\n    raise NotOneValueFound('Expected one value, found 0')\nexecuting.executing.NotOneValueFound: Expected one value, found 0\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}