{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 64148,
          "databundleVersionId": 7669720,
          "sourceType": "competition"
        },
        {
          "sourceId": 726715,
          "sourceType": "datasetVersion",
          "datasetId": 262
        },
        {
          "sourceId": 11384,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 6216
        }
      ],
      "dockerImageVersionId": 30674,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Gemma Python Chat (GPC)",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DLesmes/GPC/blob/main/Gemma_Python_Chat_(GPC).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'data-assistants-with-gemma:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F64148%2F7669720%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240408%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240408T133701Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D1a10de35a07673cb16eae1b3ebd3ef0a22e6bc86c45d6dd723be804eec329291aa632d68db8c1aaac80d3a889084598bd7c96a4e89a2ed64ec6557fe9c56c63a923ae81406fe580b2fd16c0a49a3b809a9d0e3eacb1e069af75d881620adbd8d18086e4a6c1a564e2cfdc530b7af1fdbc76231345a6af37e59ae9d7ab5f480c756a33a41b0ecffd8f7fbe14ae26d99c78d4965dfea4a2416f5fe0de35e50674fa9509c440fb55cec028072ef25ed315570c2acfc8590de796bfd9aa1afc8e49efd5e7124156b10976b84aaf044c930c3d3697e67f8eef95e6bf5372b8f49f30a13e8f54f3171102dae93275b3cc51e1270e4823e437f1ec7f02ef85429ae125f,pythonquestions:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F262%2F726715%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240408%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240408T133701Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0a6acbc2b2d12676d96d08e3f4da9ec355b07bb5163876532321b1f530c36eb664891dc0d54a9a56ae1f86f44bd2c2c2cdf9643a54c5bd2ffdd542dcf74e7c02c968a128117a2c81b8afc3c3c33b5feab5f7494dbb04755d864e3790af206c2cd98ff69dccffa6a7d2192bccb64d4a3858713c29acd5cf1d29d3e972fdebdb8da23e2125d168f528da307cacc26da22eeede271cd5a379d29c1f454019c7aaaf810c1dd493fb8314d63f598c309cc095accd7821794ba00ef53789d4cca92f8256099c7257bc999ae3ef20bb7aca26d73021da166f070b980acc9c4fea5b245d500da7cd7c637f40671ed22bdce66a66496cc18b1722f7bbad5d45e3b2c69de6,gemma/transformers/2b/2:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F6216%2F11384%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240408%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240408T133701Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D85f45f3f8b3f4c201a2936764487dd5a8e468277d88e43bd9c978307896cf6ef5834b3e29db45587b062c8154a14798fe46c9958530c49f0218bad33b48ffb88f46f72c43520ab5039fdfea4988fbb3ba147157a40b149aae224ac5ce222773df1b0e1549fc2769ed439849a42dd69d90a93f686253e9521f0f6d3430b3ac22ea1d4b1752e8a46edb5b263f7be594cf81a845e7c22219d45311b6e921414087fab6c5799e8910d0483f0e87c44fe71dd6cc24b4a9b0f405c3821cb8517f17b6f72a043c5abf88a5d253ec506608382fc78d1abada7249bf12ac6cd8e497ae51d4eb268215a1dfc341720601a9f63821513a7b7f2c1849b19e2412b4c55c2b93f'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "W6qPKHFe7VEn"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/DLesmes/GPC/blob/main/GPC_(Gemma_Python_Chat).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCP ğŸ¤– Gemma Python Chatbot"
      ],
      "metadata": {
        "id": "Qx8hbihKsoW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.ibb.co/8xZNc32/Gemma.png)"
      ],
      "metadata": {
        "id": "B0RdGIyrsoW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Gemma Python Chatbot ğŸš€ğŸš€ help you to answer common questions about the ğŸ Python programming language, powered by [Gemma 2B IT](https://blog.google/technology/developers/gemma-open-models/) updated with the Python Enhancement Proposal ([PEPs](https://peps.python.org/)) documentation using a Retrival-Augmented Generation ([RAG](https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/)) sponsored by a Chroma vectorial database using the open source embeddings [hkunlp/instructor-large](https://huggingface.co/hkunlp/instructor-large) of 768 entries, orchested by [langchaing](https://python.langchain.com/docs/use_cases/chatbots/) that is a framework that let you use differen models and less code changes on the architecture when you decide to test other providers"
      ],
      "metadata": {
        "id": "5C9kSlAVsoW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements"
      ],
      "metadata": {
        "id": "5GhJQPvLsoW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb #!pip install chromadb==0.3.26\n",
        "# !pip install ydata-profiling #!pip install ydata-profiling==4.6.1\n",
        "!pip install langchain #!pip install langchain==0.0.345 ##!pip install langchain-core==0.1.31\n",
        "#!pip install pydantic  #!pip install pydantic==1.10.14\n",
        "!pip install sentence-transformers   #!pip install sentence-transformers==2.6.1\n",
        "!pip install InstructorEmbedding  #!pip install InstructorEmbedding==1.0.1"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "scrolled": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-04-06T15:36:59.419963Z",
          "iopub.execute_input": "2024-04-06T15:36:59.420363Z",
          "iopub.status.idle": "2024-04-06T15:38:20.786377Z",
          "shell.execute_reply.started": "2024-04-06T15:36:59.420335Z",
          "shell.execute_reply": "2024-04-06T15:38:20.785355Z"
        },
        "trusted": true,
        "id": "-MfaZYz37VEs",
        "outputId": "03fb20f5-1981-41e0-8ddb-4dd2b20115f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting chromadb\n  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\nCollecting build>=1.0.3 (from chromadb)\n  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.10/site-packages (from chromadb) (2.31.0)\nRequirement already satisfied: pydantic>=1.9 in /opt/conda/lib/python3.10/site-packages (from chromadb) (2.5.3)\nCollecting chroma-hnswlib==0.7.3 (from chromadb)\n  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nRequirement already satisfied: fastapi>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.108.0)\nRequirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.25.0)\nRequirement already satisfied: numpy>=1.22.5 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.26.4)\nCollecting posthog>=2.4.0 (from chromadb)\n  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.9.0)\nCollecting pulsar-client>=3.1.0 (from chromadb)\n  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting onnxruntime>=1.14.1 (from chromadb)\n  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.15.2)\nCollecting pypika>=0.48.9 (from chromadb)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.66.1)\nRequirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (7.4.0)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb) (6.1.1)\nCollecting grpcio>=1.58.0 (from chromadb)\n  Downloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting bcrypt>=4.0.1 (from chromadb)\n  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\nRequirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.9.0)\nCollecting kubernetes>=28.1.0 (from chromadb)\n  Downloading kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: tenacity>=8.2.3 in /opt/conda/lib/python3.10/site-packages (from chromadb) (8.2.3)\nRequirement already satisfied: PyYAML>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (6.0.1)\nRequirement already satisfied: mmh3>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.1.0)\nCollecting orjson>=3.9.12 (from chromadb)\n  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging>=19.1 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (21.3)\nCollecting pyproject_hooks (from build>=1.0.3->chromadb)\n  Downloading pyproject_hooks-1.0.0-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\nRequirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.32.0.post1)\nRequirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.26.1)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\nRequirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\nRequirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\nRequirement already satisfied: urllib3>=1.24.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\nRequirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\nRequirement already satisfied: importlib-metadata<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\nRequirement already satisfied: backoff<3.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\nRequirement already satisfied: opentelemetry-proto==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\nCollecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl.metadata (6.1 kB)\nCollecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\nCollecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (69.0.3)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\nCollecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\nINFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl.metadata (6.1 kB)\nCollecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl.metadata (2.2 kB)\nCollecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-instrumentation-asgi==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\nCollecting opentelemetry-util-http==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl.metadata (2.5 kB)\nCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.6)\nRequirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.21.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\nRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.3.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=19.1->build>=1.0.3->chromadb) (3.1.1)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette<0.33.0,>=0.29.0->fastapi>=0.95.2->chromadb) (4.2.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.33.0,>=0.29.0->fastapi>=0.95.2->chromadb) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.33.0,>=0.29.0->fastapi>=0.95.2->chromadb) (1.2.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\nDownloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading build-1.2.1-py3-none-any.whl (21 kB)\nDownloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl (11 kB)\nDownloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl (14 kB)\nDownloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl (28 kB)\nDownloading opentelemetry_util_http-0.43b0-py3-none-any.whl (6.9 kB)\nDownloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\nDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=3fd597a36fd535e9e43b5b0bf5845627d3ffd3821604f8d6d98bf1f99436adc6\n  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\nSuccessfully built pypika\nInstalling collected packages: pypika, monotonic, pyproject_hooks, pulsar-client, orjson, opentelemetry-util-http, humanfriendly, grpcio, chroma-hnswlib, bcrypt, asgiref, posthog, coloredlogs, build, opentelemetry-instrumentation, onnxruntime, kubernetes, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, chromadb\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.51.1\n    Uninstalling grpcio-1.51.1:\n      Successfully uninstalled grpcio-1.51.1\n  Attempting uninstall: kubernetes\n    Found existing installation: kubernetes 26.1.0\n    Uninstalling kubernetes-26.1.0:\n      Successfully uninstalled kubernetes-26.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 29.0.0 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed asgiref-3.8.1 bcrypt-4.1.2 build-1.2.1 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 grpcio-1.60.0 humanfriendly-10.0 kubernetes-29.0.0 monotonic-1.6 onnxruntime-1.17.1 opentelemetry-instrumentation-0.43b0 opentelemetry-instrumentation-asgi-0.43b0 opentelemetry-instrumentation-fastapi-0.43b0 opentelemetry-util-http-0.43b0 orjson-3.10.0 posthog-3.5.0 pulsar-client-3.4.0 pypika-0.48.9 pyproject_hooks-1.0.0\nCollecting langchain\n  Downloading langchain-0.1.14-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\nCollecting langchain-community<0.1,>=0.0.30 (from langchain)\n  Downloading langchain_community-0.0.31-py3-none-any.whl.metadata (8.4 kB)\nCollecting langchain-core<0.2.0,>=0.1.37 (from langchain)\n  Downloading langchain_core-0.1.40-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.40-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nCollecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.37->langchain)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nDownloading langchain-0.1.14-py3-none-any.whl (812 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.1.40-py3-none-any.whl (276 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\nDownloading langsmith-0.1.40-py3-none-any.whl (87 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, langsmith, langchain-core, langchain-text-splitters, langchain-community, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.8.2 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.1.14 langchain-community-0.0.31 langchain-core-0.1.40 langchain-text-splitters-0.0.1 langsmith-0.1.40 packaging-23.2\nCollecting sentence-transformers\n  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.38.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.21.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.6.1\nCollecting InstructorEmbedding\n  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata (20 kB)\nDownloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\nInstalling collected packages: InstructorEmbedding\nSuccessfully installed InstructorEmbedding-1.0.1\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#base\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import uuid\n",
        "import time\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import *\n",
        "# variables\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "# model\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    Trainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Seq2SeqTrainingArguments,\n",
        ")\n",
        "# data\n",
        "from datasets import load_dataset\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "# embeddings\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "# vector database\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "Vq5ZFhX7soW4",
        "execution": {
          "iopub.status.busy": "2024-04-06T15:38:20.788417Z",
          "iopub.execute_input": "2024-04-06T15:38:20.788704Z",
          "iopub.status.idle": "2024-04-06T15:38:21.597466Z",
          "shell.execute_reply.started": "2024-04-06T15:38:20.788679Z",
          "shell.execute_reply": "2024-04-06T15:38:21.596715Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classes"
      ],
      "metadata": {
        "id": "1jeh0zUU7VEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions and answers data"
      ],
      "metadata": {
        "id": "yUfQ6rFQ7VEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class pythonQAData:\n",
        "    \"\"\"\n",
        "    Processes data from Questions and Answers CSV files to provide a structured Q&A format.\n",
        "\n",
        "    Attributes:\n",
        "        questions_path (str): Path to the Questions CSV file\n",
        "        answers_path (str): Path to the Answers CSV file\n",
        "        tags_path (str): Path to the tags CSV file\n",
        "\n",
        "    Methods:\n",
        "        load_data(): Loads the CSV data into DataFrames.\n",
        "        merge(): Cleans, merges, and formats the question and answer data.\n",
        "        get_formatted_qa(): Returns a list of formatted question-answer strings.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.questions_path = '../input/pythonquestions/Questions.csv'\n",
        "        self.answers_path = '../input/pythonquestions/Answers.csv'\n",
        "        self.tags_path = '../input/pythonquestions/Tags.csv'\n",
        "        self.regex = r\"<\\/?[\\w\\s]*>\"\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Loads Questions and Answers data from CSV files.\"\"\"\n",
        "        df_questions = pd.read_csv(\n",
        "            self.questions_path,\n",
        "            encoding=\"ISO-8859-1\",\n",
        "            usecols=[\n",
        "                'Id',\n",
        "                'Score',\n",
        "                'Title'\n",
        "            ]\n",
        "        )\n",
        "        df_answers = pd.read_csv(\n",
        "            self.answers_path,\n",
        "            encoding=\"ISO-8859-1\",\n",
        "            usecols=[\n",
        "                'ParentId',\n",
        "                'Score',\n",
        "                'Body'\n",
        "            ]\n",
        "        )\n",
        "        df_tags = pd.read_csv(\n",
        "            self.tags_path,\n",
        "            encoding=\"ISO-8859-1\",\n",
        "            usecols=[\n",
        "                'Id',\n",
        "                'Tag'\n",
        "            ]\n",
        "        )\n",
        "        return df_questions, df_answers, df_tags\n",
        "\n",
        "\n",
        "    def qa_data(self):\n",
        "        \"\"\"Cleans, merges, and formats the question and answer data.\"\"\"\n",
        "        df_questions, df_answers, df_tags = self.load_data()\n",
        "        # Rename\n",
        "        df_questions.rename(\n",
        "            columns={\n",
        "                'Title': 'Question',\n",
        "                'Score': 'question_score'\n",
        "            },\n",
        "            inplace=True\n",
        "        )\n",
        "        df_answers.rename(\n",
        "            columns={\n",
        "                'Body': 'Answer',\n",
        "                'ParentId':'Id',\n",
        "                'Score': 'answer_score'\n",
        "            },\n",
        "            inplace=True\n",
        "        )\n",
        "        # Filter by score\n",
        "        df_questions = df_questions[df_questions['question_score'] > 5].copy()\n",
        "        # Sort and deduplicate answers\n",
        "        df_answers = df_answers.sort_values(\n",
        "            'answer_score',\n",
        "            ascending=False\n",
        "        ).drop_duplicates(subset=['Id'])\n",
        "        # Merge\n",
        "        df_qa = df_questions.merge(\n",
        "            df_answers,\n",
        "            how='left',\n",
        "            on='Id'\n",
        "        ).merge(\n",
        "            df_tags,\n",
        "            how='left',\n",
        "            on='Id'\n",
        "        )\n",
        "        # filter for python  questions\n",
        "        df_qa = df_qa[df_qa['answer_score'] > 5].copy()\n",
        "        df_qa = df_qa[df_qa['Tag']=='python'].copy()\n",
        "        df_qa['Answer'] = df_qa['Answer'].apply(\n",
        "            lambda x: re.sub(\n",
        "                self.regex,\n",
        "                \"\",\n",
        "                x\n",
        "            )\n",
        "        )\n",
        "        return df_qa\n",
        "\n",
        "    def get_fine_tunning_data(self):\n",
        "        \"\"\"Returns a list of formatted user-assistant strings.\"\"\"\n",
        "        df_qa_data = self.qa_data()\n",
        "        data = [\n",
        "            f\"<-change-of-interlocutor->user:\\n{row['Question']}\\n<-change-of-interlocutor->assistant:\\n{row['Answer']}\"\n",
        "            for index, row\n",
        "            in df_qa_data.iterrows()\n",
        "        ]\n",
        "        return data\n",
        "    def get_qa_data(self):\n",
        "        \"\"\"Returns a list of records dictionaries \"\"\"\n",
        "        df_qa_data = self.qa_data()\n",
        "        data = df_qa_data[\n",
        "            [\n",
        "                'Question',\n",
        "                'Answer'\n",
        "            ]\n",
        "        ].to_dict(orient='records')\n",
        "        return data\n"
      ],
      "metadata": {
        "id": "bSU-ohmssoW5",
        "execution": {
          "iopub.status.busy": "2024-04-06T15:38:21.598709Z",
          "iopub.execute_input": "2024-04-06T15:38:21.599001Z",
          "iopub.status.idle": "2024-04-06T15:38:21.61442Z",
          "shell.execute_reply.started": "2024-04-06T15:38:21.598978Z",
          "shell.execute_reply": "2024-04-06T15:38:21.613606Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python Enhancement Proposals data"
      ],
      "metadata": {
        "id": "sVIpcdN87VEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Peps:\n",
        "    \"\"\"\n",
        "    Scrapes Python Enhancement Proposals (PEPs) from https://peps.python.org/\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initiates the scraping process.\"\"\"\n",
        "        self.base_url = 'https://peps.python.org/'\n",
        "\n",
        "    def scraper(self, url):\n",
        "        \"\"\"\n",
        "        Fetches the HTML content of a given URL.\n",
        "\n",
        "        Args:\n",
        "            url (str): The URL to fetch.\n",
        "\n",
        "        Returns:\n",
        "            BeautifulSoup: A BeautifulSoup object representing the parsed HTML.\n",
        "        \"\"\"\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        return BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    def _fetch_pep_links(self):\n",
        "        \"\"\"Fetches links to individual PEP pages (private method).\n",
        "\n",
        "        Returns:\n",
        "            list: A list of PEP URLs.\n",
        "        \"\"\"\n",
        "        soup = self.scraper(self.base_url)\n",
        "        return list(\n",
        "            set(\n",
        "                [\n",
        "                    self.base_url + ref['href']\n",
        "                    for ref in soup.find_all('a', class_='pep reference internal')\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def _download_peps(self):\n",
        "        \"\"\"Downloads the content of individual PEPs (private method).\n",
        "\n",
        "        Returns:\n",
        "            list: A list of BeautifulSoup objects representing individual PEPs.\n",
        "        \"\"\"\n",
        "        pep_links = self._fetch_pep_links()\n",
        "        return [self.scraper(pep_link) for pep_link in pep_links]\n",
        "\n",
        "    def scrape(self):\n",
        "        \"\"\"Extracts the relevant text content from each PEP.\n",
        "\n",
        "        Returns:\n",
        "            list: A list of text strings, each representing the content of a PEP.\n",
        "        \"\"\"\n",
        "        pep_soups = self._download_peps()\n",
        "        return [\n",
        "            '\\n'.join([word.text.replace('\"\"\"',\"'\") for word in soup.find_all('section')])\n",
        "            for soup in pep_soups\n",
        "        ]\n",
        "\n",
        "    def jsonl_format(self):\n",
        "        \"\"\"Format the spcraped data to a jsonl format is it alist of dictionaries\n",
        "        Returns:\n",
        "            list: A list of dictionaries with the following:\n",
        "                page_content: The content of each section scraped\n",
        "                source: The linke where it was scraped\n",
        "        \"\"\"\n",
        "        source_links = self._fetch_pep_links()\n",
        "        pep_content = self.scrape()\n",
        "        pep_data = dict(zip(source_links,pep_content))\n",
        "        return [\n",
        "            {\n",
        "                'text': value,\n",
        "                'source': key\n",
        "            }\n",
        "            for key, value in pep_data.items()\n",
        "        ]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:38:21.616487Z",
          "iopub.execute_input": "2024-04-06T15:38:21.616756Z",
          "iopub.status.idle": "2024-04-06T15:38:21.63659Z",
          "shell.execute_reply.started": "2024-04-06T15:38:21.616734Z",
          "shell.execute_reply": "2024-04-06T15:38:21.635752Z"
        },
        "trusted": true,
        "id": "pHTRK6MR7VEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embeddings"
      ],
      "metadata": {
        "id": "QX6y4LlW7VEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeder:\n",
        "    \"\"\"\n",
        "    Creates text document embeddings (numerical representations) for semantic search,\n",
        "    similarity comparison, and related natural language processing tasks. Offers the choice\n",
        "    between a larger model for richer embeddings or a smaller, more efficient model.\n",
        "\n",
        "    Attributes:\n",
        "        large (bool): Controls the size of the embedding model. When set to True, uses a\n",
        "                      larger model for richer embeddings (default: True).\n",
        "        model (str): The name of the embedding model to use. Changes based on the value of 'large'.\n",
        "        device (str): The device to use for computation. Options include \"cpu\" or, if available, \"cuda\"\n",
        "                      for GPU acceleration (default: \"cuda\").\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, large: bool = False):\n",
        "        \"\"\"\n",
        "        Initializes the Embeder instance with preferences for model size.\n",
        "\n",
        "        Args:\n",
        "            large (bool, optional): If True, initializes with the larger embedding model.\n",
        "                                    Defaults to False for the smaller, faster model.\n",
        "        \"\"\"\n",
        "        self.large = large\n",
        "        if self.large:\n",
        "            self.model = \"hkunlp/instructor-large\"\n",
        "            self.device = \"cuda\"  # If GPU is available\n",
        "        else:\n",
        "            self.model = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "\n",
        "    def instructor(self):\n",
        "        \"\"\"\n",
        "        Configures the embedding pipeline based on the selected model size.\n",
        "\n",
        "        Returns:\n",
        "           An embedding object from either the HuggingFaceInstructEmbeddings class\n",
        "           (for the large model) or the SentenceTransformerEmbeddings class (for the smaller model).\n",
        "        \"\"\"\n",
        "        if self.large:\n",
        "            embed = HuggingFaceInstructEmbeddings(\n",
        "                model_name=self.model,\n",
        "                model_kwargs={\"device\": self.device}\n",
        "            )\n",
        "        else:\n",
        "            embed = SentenceTransformerEmbeddings(model_name=self.model)\n",
        "        return embed\n",
        "\n",
        "    def run(self, docs_list: list):\n",
        "        \"\"\"\n",
        "        Generates embeddings for a given list of text documents.\n",
        "\n",
        "        Args:\n",
        "            docs_list (list): A list of text documents to embed.\n",
        "\n",
        "        Returns:\n",
        "            List[List[float]]: A list of lists, where each inner list represents the\n",
        "                               numerical embedding for a corresponding document in the input.\n",
        "        \"\"\"\n",
        "        if docs_list is None:\n",
        "            docs_list = ['']  # Prevent errors with empty input\n",
        "\n",
        "        embed = self.instructor()  # Get the appropriate embedding object\n",
        "        return embed.embed_documents(docs_list)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T16:08:22.225595Z",
          "iopub.execute_input": "2024-04-06T16:08:22.22631Z",
          "iopub.status.idle": "2024-04-06T16:08:22.235656Z",
          "shell.execute_reply.started": "2024-04-06T16:08:22.226279Z",
          "shell.execute_reply": "2024-04-06T16:08:22.234833Z"
        },
        "trusted": true,
        "id": "L6tqFCWE7VEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt"
      ],
      "metadata": {
        "id": "D2kTXqsP7VEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_config = [{\n",
        "    \"prompt_id\": \"0.0.1\",\n",
        "    \"supplier\": \"google\",\n",
        "    \"system\": \"\"\"\n",
        "Act as a Python programming language expert assistant\n",
        "your goal is to answer common questions in a clear, comprehensive, and accurate way, taking into account this guidelines:\n",
        "1. When responding, incorporate any relevant context to enhance the accuracy and informativeness of your answers using the documentation provided if it is necesary\n",
        "2. Please structure your response to include definitions, examples, and any relevant comparisons to other statistical measures\n",
        "3. Aim for plain language to ensure accessibility for all users\n",
        "4. If the question is off topic about programing lenguage you MUST to say \"I'm here to help you with Python programming language questions only, excuse me\"\n",
        "5. You can say hello if you are greeted\n",
        "        \"\"\",\n",
        "    \"technical_documentation\": \"\\n\\nTake into account this technical documentation found:\\n{technical_documentation}\",\n",
        "    \"model\": \"/kaggle/input/gemma/transformers/2b/2\",\n",
        "    \"temperature\": 0,\n",
        "    \"max_length\": 250,\n",
        "    \"max_tokens\": 830,\n",
        "    \"top_p\": 1,\n",
        "    \"frequency_penalty\": 0,\n",
        "    \"presence_penalty\": 0\n",
        "},\n",
        "{\n",
        "    \"prompt_id\": \"0.0.2\",\n",
        "    \"supplier\": \"google\",\n",
        "    \"system\": \"\"\"\n",
        "Act as a Python programming language expert assistant\n",
        "your goal is to answer common questions in a clear, comprehensive, and accurate way, taking into account this guidelines:\n",
        "1. When responding, incorporate any relevant context to enhance the accuracy and informativeness of your answers using the documentation provided if it is necesary\n",
        "2. Please structure your response to include definitions, examples, and any relevant comparisons to other statistical measures\n",
        "3. Aim for plain language to ensure accessibility for all users\n",
        "4. If the question is off topic about programing lenguage you MUST to say \"I'm here to help you with Python programming language questions only, excuse me\"\n",
        "5. You can say hello if you are greeted\n",
        "6. DO NOT repeat more than twice the same sentence!\n",
        "\n",
        "TAKE A DEEP BREATH AND PAY ATTENTION TO THE USER QUESTION\n",
        "\n",
        "For each question you answer perfectly, I will pay you USD 1000.00, may be more for the consecutive accurate and correct answer\n",
        "        \"\"\",\n",
        "    \"technical_documentation\": \"\\n\\nTake into account this technical documentation found:\\n{technical_documentation}\",\n",
        "    \"model\": \"/kaggle/input/gemma/transformers/2b/2\",\n",
        "    \"temperature\": 1,\n",
        "    \"max_length\": 4096,\n",
        "    \"max_tokens\": 830,\n",
        "    \"top_p\": 1,\n",
        "    \"frequency_penalty\": 0,\n",
        "    \"presence_penalty\": 0\n",
        "},\n",
        "{\n",
        "    \"prompt_id\": \"0.0.3\",\n",
        "    \"supplier\": \"google\",\n",
        "    \"system\": \"\"\"\n",
        "Act as a Python programming language expert assistant\n",
        "your goal is to answer common questions in a clear, comprehensive, and accurate way, taking into account this guidelines:\n",
        "1. When responding, incorporate any relevant context to enhance the accuracy and informativeness of your answers using the documentation provided if it is necesary\n",
        "2. Please structure your response to include definitions, examples, and any relevant comparisons to other statistical measures\n",
        "3. Aim for plain language to ensure accessibility for all users\n",
        "4. If the question is off topic about programing lenguage you MUST to say \"I'm here to help you with Python programming language questions only, excuse me\"\n",
        "5. You can say hello if you are greeted\n",
        "6. DO NOT repeat more than twice the same sentence!\n",
        "\n",
        "TAKE A DEEP BREATH AND PAY ATTENTION TO THE USER QUESTION\n",
        "\n",
        "For each question you answer perfectly, I will pay you USD 1000.00, may be more for the consecutive accurate and correct answer\n",
        "        \"\"\",\n",
        "    \"technical_documentation\": \"\\n\\nTake into account this technical documentation found:\\n{technical_documentation}\",\n",
        "    \"model\": \"/kaggle/input/gemma/transformers/2b/2\",\n",
        "    \"temperature\": 0,\n",
        "    \"max_length\": 2048,\n",
        "    \"max_tokens\": 830,\n",
        "    \"top_p\": 1,\n",
        "    \"frequency_penalty\": 0,\n",
        "    \"presence_penalty\": 0\n",
        "}]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:38:21.653796Z",
          "iopub.execute_input": "2024-04-06T15:38:21.654073Z",
          "iopub.status.idle": "2024-04-06T15:38:21.669875Z",
          "shell.execute_reply.started": "2024-04-06T15:38:21.65405Z",
          "shell.execute_reply": "2024-04-06T15:38:21.66904Z"
        },
        "trusted": true,
        "id": "9xnk1zDh7VEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Settings"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-04T05:03:58.746391Z",
          "iopub.execute_input": "2024-04-04T05:03:58.746828Z",
          "iopub.status.idle": "2024-04-04T05:03:58.751668Z",
          "shell.execute_reply.started": "2024-04-04T05:03:58.746794Z",
          "shell.execute_reply": "2024-04-04T05:03:58.750527Z"
        },
        "id": "UH5vVmWP7VEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Settings:\n",
        "    \"\"\"\n",
        "    Manages and loads external configuration secrets for the application.  Utilizes a UserSecretsClient\n",
        "    to securely retrieve sensitive configuration values.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initializes the Settings class and retrieves configuration secrets.\n",
        "        \"\"\"\n",
        "        self.user_secrets = UserSecretsClient()  # Create an instance for accessing secrets\n",
        "\n",
        "        # Load individual secrets (add descriptions for clarity)\n",
        "        self.CHUNK_SIZE = self.user_secrets.get_secret(\"CHUNK_SIZE\")  # The size of data chunks for processing\n",
        "        self.CHUNK_OVERLAP = self.user_secrets.get_secret(\"CHUNK_OVERLAP\")  # Ooverlap between data chunks\n",
        "        self.CHROMA_NAME_INDEX = self.user_secrets.get_secret(\"CHROMA_NAME_INDEX\")  # Vectorial Database identifier\n",
        "        self.K = self.user_secrets.get_secret(\"K\")  # Could be a parameter for an algorithm\n",
        "        self.NN_THRESHOLD = self.user_secrets.get_secret(\"NN_THRESHOLD\")  # A threshold for a neural network or similarity metric\n",
        "        self.PROMPT_ID = self.user_secrets.get_secret(\"PROMPT_ID\")  # An identifier for a prompt (likely in a text-based task and configs)\n",
        "\n",
        "        # Given that 'prompt_config' is teh previous source of prompt definitions:\n",
        "        self.prompt = [prompt for prompt in prompt_config if prompt['prompt_id'] == self.PROMPT_ID][0]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:38:21.670798Z",
          "iopub.execute_input": "2024-04-06T15:38:21.671025Z",
          "iopub.status.idle": "2024-04-06T15:38:21.683841Z",
          "shell.execute_reply.started": "2024-04-06T15:38:21.671006Z",
          "shell.execute_reply": "2024-04-06T15:38:21.682969Z"
        },
        "trusted": true,
        "id": "RsltcLo47VEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retriever"
      ],
      "metadata": {
        "id": "FQL9t9bO7VEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeder = Embeder()\n",
        "settings = Settings()\n",
        "class Retriever:\n",
        "    \"\"\"\n",
        "    Retrieves relevant text chunks from a Chroma vectorial database based on a query. Leverages external\n",
        "    configuration settings (Settings) and an embedding model (Embeder).\n",
        "\n",
        "    Handles text splitting, vector database loading, and querying.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initializes the Retriever class. Configures the text splitter using settings and stores the\n",
        "        index name for the Chroma database.\n",
        "        \"\"\"\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=int(settings.CHUNK_SIZE),\n",
        "            length_function=len,\n",
        "            chunk_overlap=int(settings.CHUNK_OVERLAP)\n",
        "        )\n",
        "        self.index_name = settings.CHROMA_NAME_INDEX\n",
        "\n",
        "    def load(self, data: list[dict]):\n",
        "        \"\"\"\n",
        "        Loads and preprocesses data for storage in the Chroma database.\n",
        "\n",
        "        Args:\n",
        "            data (list[dict]): A list of dictionaries, each containing text content and optional metadata.\n",
        "\n",
        "        Returns:\n",
        "            list[Document]: A list of Document objects formatted for Chroma.\n",
        "        \"\"\"\n",
        "        documents = []\n",
        "        for obj in data:\n",
        "            page_content = obj.get(\"text\", \"\")\n",
        "            metadata = {\n",
        "                \"source\": obj.get(\"source\", \"local\")\n",
        "            }\n",
        "            documents.append(Document(page_content=page_content, metadata=metadata))\n",
        "        return documents\n",
        "\n",
        "    def set(self, data: list[dict]):\n",
        "        \"\"\"\n",
        "        Updates the Chroma vectorial database with new data.\n",
        "\n",
        "        Args:\n",
        "            data (list[dict]): A list of dictionaries, each containing text content and optional metadata.\n",
        "        \"\"\"\n",
        "        data = self.load(data)  # Preprocess data\n",
        "        documents = self.text_splitter.split_documents(data)  # Split into chunks\n",
        "\n",
        "        # Generate embeddings\n",
        "        instructor = embeder.instructor()\n",
        "        vector_db = Chroma.from_documents(\n",
        "            documents=documents,\n",
        "            embedding=instructor,\n",
        "            persist_directory=self.index_name\n",
        "        )\n",
        "        vector_db.persist()  # Store the database\n",
        "\n",
        "    def query(\n",
        "            self,\n",
        "            message: str,\n",
        "            k: int = int(settings.K),\n",
        "            threshold: float = float(settings.NN_THRESHOLD)\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Retrieves the most similar text chunks from the Chroma database based on a given query.\n",
        "\n",
        "        Args:\n",
        "            message (str): The query text.\n",
        "            k (int, optional): The number of similar chunks to retrieve (default from settings).\n",
        "            threshold (float, optional): The similarity threshold to filter results (default from settings).\n",
        "\n",
        "        Returns:\n",
        "            list[str]: A list of similar text chunks, filtered by the threshold.\n",
        "        \"\"\"\n",
        "        # Load the Chroma database\n",
        "        vectorial_db = Chroma(\n",
        "            embedding_function=embeder.instructor(),\n",
        "            persist_directory=self.index_name\n",
        "        )\n",
        "\n",
        "        # Perform the similarity search\n",
        "        res = vectorial_db.similarity_search_with_score(message, k=k)\n",
        "\n",
        "        # Filter and return results\n",
        "        relevant_results = list(\n",
        "            set(  # Remove duplicates\n",
        "                [\n",
        "                    vector[0].page_content\n",
        "                    for vector in res\n",
        "                    if vector[1] < threshold  # Apply similarity threshold\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "        return [\n",
        "            result.replace('\"\"\"',\"'\") # cleaning posible docString retrived from documented code\n",
        "            for result\n",
        "            in relevant_results\n",
        "        ]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T16:08:29.768838Z",
          "iopub.execute_input": "2024-04-06T16:08:29.769158Z",
          "iopub.status.idle": "2024-04-06T16:08:32.073925Z",
          "shell.execute_reply.started": "2024-04-06T16:08:29.769134Z",
          "shell.execute_reply": "2024-04-06T16:08:32.072999Z"
        },
        "trusted": true,
        "id": "NLxqbu8d7VEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Message"
      ],
      "metadata": {
        "id": "wRHIpROr7VEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "settings = Settings()\n",
        "class Message:\n",
        "    \"\"\"\n",
        "    Represents a message within a conversational context. Stores information about the message's role,\n",
        "    content, timestamp, and manages saving and loading conversation history.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, role: str, content: str, timestamp: str = int(time.time()), prompt_id: str = settings.PROMPT_ID):\n",
        "        \"\"\"\n",
        "        Initializes a Message object.\n",
        "\n",
        "        Args:\n",
        "            role (str): Indicates the role of the sender (e.g., 'user', 'system').\n",
        "            content (str): The text content of the message.\n",
        "            timestamp (str, optional): A timestamp for the message (defaults to the current time).\n",
        "            prompt_id (str, optional): Identifier relating to a specific prompt configuration (from settings).\n",
        "        \"\"\"\n",
        "\n",
        "        self.reply_id = str(uuid.uuid4())  # Generate a unique ID for the message\n",
        "        self.role = role\n",
        "        self.content = content\n",
        "        self.timestamp = timestamp\n",
        "        self.file = 'data/history.json'  # File for storing conversation history\n",
        "\n",
        "        # Ensure the history file exists\n",
        "        if not os.path.exists(self.file):\n",
        "            json.dump([], open(self.file, 'w'))  # Create an empty file if it doesn't exist\n",
        "\n",
        "    def reply(self):\n",
        "        \"\"\"\n",
        "        Formats a basic reply message structure.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the message's reply ID, role, content, and timestamp.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'reply_id': self.reply_id,\n",
        "            'role': self.role,\n",
        "            'content': self.content,\n",
        "            'timestamp': self.timestamp\n",
        "        }\n",
        "\n",
        "    def system_reply(self):\n",
        "        \"\"\"\n",
        "        Generates a system reply using the prompt configuration.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the system reply, including ID, role, timestamp,\n",
        "                  and text content derived from settings.\n",
        "        \"\"\"\n",
        "        prompt = settings.prompt\n",
        "        return {\n",
        "            'reply_id': self.reply_id,\n",
        "            'role': 'system',\n",
        "            'content': prompt['system'],\n",
        "            'timestamp': self.timestamp\n",
        "        }\n",
        "\n",
        "    def new_chat(self):\n",
        "        \"\"\"\n",
        "        Starts a new chat by initializing the history file.\n",
        "\n",
        "        Returns:\n",
        "            list: A list with the initial system reply and the user's message.\n",
        "        \"\"\"\n",
        "        init_chat = [self.system_reply(), self.reply()]\n",
        "        json.dump(init_chat, open(self.file, 'w'))\n",
        "        return init_chat\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"\n",
        "        Updates the conversation history file by appending the current reply.\n",
        "        \"\"\"\n",
        "        dict_history = json.load(open(self.file))\n",
        "        dict_history.append(self.reply())\n",
        "        json.dump(dict_history, open(self.file, 'w'))\n",
        "\n",
        "    def restart_history(self):\n",
        "        \"\"\"\n",
        "        Clears the conversation history file.\n",
        "        \"\"\"\n",
        "        json.dump([], open(self.file, 'w'))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:38:23.992377Z",
          "iopub.execute_input": "2024-04-06T15:38:23.992684Z",
          "iopub.status.idle": "2024-04-06T15:38:26.085967Z",
          "shell.execute_reply.started": "2024-04-06T15:38:23.99266Z",
          "shell.execute_reply": "2024-04-06T15:38:26.085226Z"
        },
        "trusted": true,
        "id": "ayVaaebR7VEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Gemma"
      ],
      "metadata": {
        "id": "p5XUIn0d7VEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Gemma:\n",
        "    \"\"\"\n",
        "    Implements a conversational AI chatbot powered by Gemma large language model. Initializes the model,\n",
        "    tokenizer, and prepares settings from a configuration.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initializes the Gemma chatbot instance.\n",
        "\n",
        "        Loads the language model and its corresponding tokenizer from the settings configuration.\n",
        "        Prepares the model for use on a GPU (if available).\n",
        "        \"\"\"\n",
        "        self.prompt = settings.prompt  # Load prompt settings\n",
        "\n",
        "        # Load language model and tokenizer\n",
        "        self.model_checkpoint = self.prompt['model']\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_checkpoint)\n",
        "        self.gemma = AutoModelForCausalLM.from_pretrained(\n",
        "            self.model_checkpoint,\n",
        "            torch_dtype=torch.float16  # Use half-precision for efficiency (if supported)\n",
        "        ).cuda()  # Move model to GPU (if available)\n",
        "\n",
        "    def chat(self, context: str):\n",
        "        \"\"\"\n",
        "        Generates a chatbot response based on the provided conversational context.\n",
        "\n",
        "        Args:\n",
        "            context (str): The conversational input text.\n",
        "\n",
        "        Returns:\n",
        "            str: The generated text response from the chatbot.\n",
        "        \"\"\"\n",
        "        # Prepare input for the language model\n",
        "        input_text = context\n",
        "        input_ids = self.tokenizer(input_text, return_tensors=\"pt\")\n",
        "        input_ids = {\n",
        "            k: v.to(\"cuda\") for k, v in input_ids.items()  # Move tensors to GPU\n",
        "        }\n",
        "\n",
        "        # Generate a response with the language model\n",
        "        outputs = self.gemma.generate(\n",
        "            **input_ids,\n",
        "            max_length=self.prompt['max_length']  # Control response length\n",
        "        )\n",
        "\n",
        "        # Decode and return the generated text\n",
        "        return self.tokenizer.decode(outputs[0])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:38:26.089271Z",
          "iopub.execute_input": "2024-04-06T15:38:26.089533Z",
          "iopub.status.idle": "2024-04-06T15:38:26.097574Z",
          "shell.execute_reply.started": "2024-04-06T15:38:26.089512Z",
          "shell.execute_reply": "2024-04-06T15:38:26.096694Z"
        },
        "trusted": true,
        "id": "kikd3QNP7VEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Expert Python Agent/Assistant"
      ],
      "metadata": {
        "id": "wydvJqXD7VEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = Retriever()\n",
        "gemma = Gemma()\n",
        "\n",
        "class Agent:\n",
        "    \"\"\"\n",
        "    Implements a conversational AI agent that leverages a knowledge database for information retrieval\n",
        "    and integrates with a generative language model (Gemma) for response generation. Manages conversation\n",
        "    history and question-answering logic.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initializes the Agent, loading prompt settings and ensuring the conversation history file exists.\n",
        "        \"\"\"\n",
        "        self.prompt = settings.prompt\n",
        "        self.file = 'data/history.json'\n",
        "        if not os.path.exists(self.file):\n",
        "            json.dump([], open(self.file, 'w'))  # Create an empty file if necessary\n",
        "\n",
        "        self.token = '\\n<-change-of-interlocutor->'  # Token to separate speakers in the chat history\n",
        "\n",
        "    def augmented_question(self, question: str):\n",
        "        \"\"\"\n",
        "        Enhances the user's question with relevant technical documentation.\n",
        "\n",
        "        Args:\n",
        "            question (str): The user's original question.\n",
        "\n",
        "        Returns:\n",
        "            str: The question augmented with technical documentation (if found), otherwise the original question.\n",
        "        \"\"\"\n",
        "        tech_docs = retriever.query(question)\n",
        "        if len(tech_docs) > 0:\n",
        "            docs = self.prompt['technical_documentation']\n",
        "            tech_docs = '\\n* '.join(tech_docs)\n",
        "            docs = docs.format(technical_documentation=tech_docs)\n",
        "            augmented_reply = f\"\"\"{question}{docs}\"\"\"\n",
        "            return augmented_reply\n",
        "        else:\n",
        "            return question\n",
        "\n",
        "    def memory(self, question: str):\n",
        "        \"\"\"\n",
        "        Prepares the conversational context (memory) for the language model.\n",
        "\n",
        "        Args:\n",
        "            question (str): The user's current question.\n",
        "\n",
        "        Returns:\n",
        "            str: Formatted conversation history with a clear separation between speakers, ready\n",
        "                 for input to the language model.\n",
        "        \"\"\"\n",
        "\n",
        "        dict_history = json.load(open(self.file))\n",
        "        message = Message(\n",
        "            role='user',\n",
        "            content=self.augmented_question(question)\n",
        "        )\n",
        "\n",
        "        if len(dict_history) > 0:\n",
        "            message.update()  # Add the latest message to history\n",
        "            full_chat = json.load(open(self.file))\n",
        "        else:\n",
        "            full_chat = message.new_chat()  # Start a new conversation\n",
        "\n",
        "        return '\\n'.join(\n",
        "            [\n",
        "                self.token + reply['role'] + ': ' + reply['content']\n",
        "                for reply in full_chat\n",
        "            ]\n",
        "        ) + self.token + 'assistant:'\n",
        "\n",
        "    def get_answer(self, full_response: str, question: str):\n",
        "        \"\"\"\n",
        "        Extracts the relevant answer from the language model's generated response.\n",
        "\n",
        "        Args:\n",
        "            full_response (str): The complete response generated by the language model.\n",
        "            question (str): The user's original question.\n",
        "\n",
        "        Returns:\n",
        "            str: The extracted answer.\n",
        "        \"\"\"\n",
        "\n",
        "        answer_list = full_response.split(self.token)\n",
        "        pos_list = [\n",
        "            pos\n",
        "            for pos, answer\n",
        "            in enumerate(answer_list)\n",
        "            if question in answer\n",
        "        ]\n",
        "        tokened_answer = answer_list[pos_list[0] + 1]\n",
        "        answer = tokened_answer.split('assistant:')[1]\n",
        "        message = Message(\n",
        "            role='assistant',\n",
        "            content=answer\n",
        "        )\n",
        "        message.update()  # Update conversation history\n",
        "        return answer\n",
        "\n",
        "    def chat(self, question: str, verbose: bool = False):\n",
        "        \"\"\"\n",
        "        Manages the core interaction with the Agent.\n",
        "\n",
        "        Args:\n",
        "            question (str): The user's query.\n",
        "            verbose (bool, optional): If True, prints the language model's full response (default: False).\n",
        "\n",
        "        Returns:\n",
        "            str: The Agent's answer to the user's question.\n",
        "        \"\"\"\n",
        "\n",
        "        memory = self.memory(question)  # Build conversational context\n",
        "        full_response = gemma.chat(context=memory)  # Generate response\n",
        "        if verbose:\n",
        "            print(full_response)\n",
        "        answer = self.get_answer(full_response, question)  # Extract the answer\n",
        "        return answer\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T16:08:41.064368Z",
          "iopub.execute_input": "2024-04-06T16:08:41.064727Z",
          "iopub.status.idle": "2024-04-06T16:08:46.938455Z",
          "shell.execute_reply.started": "2024-04-06T16:08:41.0647Z",
          "shell.execute_reply": "2024-04-06T16:08:46.937469Z"
        },
        "trusted": true,
        "id": "B3uJHzD97VEw",
        "outputId": "d9585791-d5f3-4330-a858-6ee1dbacc02f",
        "colab": {
          "referenced_widgets": [
            "11bb934e01d4469b903a87b9ed1abcaa"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11bb934e01d4469b903a87b9ed1abcaa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "r8OX7Xe-soW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fine-tunning data"
      ],
      "metadata": {
        "id": "cE-h8Qk17VEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "PythonQAData = pythonQAData()\n",
        "python_qa = PythonQAData.get_qa_data()\n",
        "print(python_qa[1486])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:39:04.979208Z",
          "iopub.execute_input": "2024-04-06T15:39:04.979486Z",
          "iopub.status.idle": "2024-04-06T15:39:37.432762Z",
          "shell.execute_reply.started": "2024-04-06T15:39:04.979463Z",
          "shell.execute_reply": "2024-04-06T15:39:37.431812Z"
        },
        "trusted": true,
        "id": "u-rFP6K07VEw",
        "outputId": "2647fde4-745f-4a4c-95bf-f1a58876ae19"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'Question': 'How can I split a file in python?', 'Answer': \"This one splits a file up by newlines and writes it back out. You can change the delimiter easily. This can also handle uneven amounts as well, if you don't have a multiple of splitLen lines (20 in this example) in your input file.\\n\\nsplitLen = 20         # 20 lines per file\\noutputBase = 'output' # output.1.txt, output.2.txt, etc.\\n\\n# This is shorthand and not friendly with memory\\n# on very large files (Sean Cavanagh), but it works.\\ninput = open('input.txt', 'r').read().split('\\\\n')\\n\\nat = 1\\nfor lines in range(0, len(input), splitLen):\\n    # First, get the list slice\\n    outputData = input[lines:lines+splitLen]\\n\\n    # Now open the output file, join the new slice with newlines\\n    # and write it out. Then close the file.\\n    output = open(outputBase + str(at) + '.txt', 'w')\\n    output.write('\\\\n'.join(outputData))\\n    output.close()\\n\\n    # Increment the counter\\n    at += 1\\n\\n\"}\nCPU times: user 16.2 s, sys: 998 ms, total: 17.2 s\nWall time: 32.4 s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "'\\n* Mean lenght of a python common question:',\n",
        "sum([len(q['Question']) for q in python_qa])/len(python_qa),\n",
        "'\\n* Standard deviation of length a common Python question:',\n",
        "np.std([len(q['Question']) for q in python_qa])\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:39:37.433931Z",
          "iopub.execute_input": "2024-04-06T15:39:37.434228Z",
          "iopub.status.idle": "2024-04-06T15:39:37.457356Z",
          "shell.execute_reply.started": "2024-04-06T15:39:37.434197Z",
          "shell.execute_reply": "2024-04-06T15:39:37.45641Z"
        },
        "trusted": true,
        "id": "A0qMZMtt7VEw",
        "outputId": "8f3fca32-b811-4c88-aea8-73dc8ee418fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\n* Mean lenght of a python common question: 50.4238285354066 \n* Standard deviation of length a common Python question: 18.168485523170148\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "PythonQAData = pythonQAData()\n",
        "python_context = PythonQAData.get_fine_tunning_data()\n",
        "print(\n",
        "    'Python Questions loaded:',\n",
        "    len(python_context),\n",
        "    '\\n',\n",
        "    '\\nSample question-answer:\\n',\n",
        "    python_context[-1][:1000]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:39:37.458691Z",
          "iopub.execute_input": "2024-04-06T15:39:37.459029Z",
          "iopub.status.idle": "2024-04-06T15:39:55.558739Z",
          "shell.execute_reply.started": "2024-04-06T15:39:37.458999Z",
          "shell.execute_reply": "2024-04-06T15:39:55.55782Z"
        },
        "trusted": true,
        "id": "QeJA4Spv7VEw",
        "outputId": "fe8f6708-94f7-437a-b99e-7a739bdb13f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Python Questions loaded: 33313 \n \nSample question-answer:\n <-change-of-interlocutor->user:\nWhy can yield be indexed?\n<-change-of-interlocutor->assistant:\nYou are not indexing. You are yielding a list; the expression yield[0] is really just the same as the following (but without a variable):\n\nlst = [0]\nyield lst\n\n\nIf you look at what next() returned you'd have gotten that list:\n\n&gt;&gt;&gt; def gen1():\n...   t = yield[0]\n...   assert t\n...   yield False\n...\n&gt;&gt;&gt; g = gen1()\n&gt;&gt;&gt; next(g)\n[0]\n\n\nYou don't have to have a space between yield and the [0], that's all.\n\nThe exception is caused by you trying to apply the subscription to the contained 0 integer:\n\n&gt;&gt;&gt; [0]        # list with one element, the int value 0\n[0]\n&gt;&gt;&gt; [0][0]     # indexing the first element, so 0\n0\n&gt;&gt;&gt; [0][0][0]  # trying to index the 0\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: 'int' object is not subscriptable\n\n\nIf you want to index a value sent to the generator, put parentheses arou\nCPU times: user 17.6 s, sys: 490 ms, total: 18.1 s\nWall time: 18.1 s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## few-shot data"
      ],
      "metadata": {
        "id": "pT1r5ZMc7VEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_list=[7,6009,12,36,8034,130,141,537,1057,5042]\n",
        "for i, q in enumerate(few_shot_list):\n",
        "    print('_'*100,f'\\n{i}.',python_qa[q])"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-04-06T15:39:55.56009Z",
          "iopub.execute_input": "2024-04-06T15:39:55.56072Z",
          "iopub.status.idle": "2024-04-06T15:39:55.566768Z",
          "shell.execute_reply.started": "2024-04-06T15:39:55.560676Z",
          "shell.execute_reply": "2024-04-06T15:39:55.565856Z"
        },
        "trusted": true,
        "id": "V4FFNUch7VEx",
        "outputId": "49c59807-b8cd-4367-db5f-8a31033275ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "____________________________________________________________________________________________________ \n0. {'Question': \"How do I use Python's itertools.groupby()?\", 'Answer': 'As Sebastjan said, you first have to sort your data. This is important.\\n\\nThe part I didn\\'t get is that in the example construction\\n\\ngroups = []\\nuniquekeys = []\\nfor k, g in groupby(data, keyfunc):\\n   groups.append(list(g))    # Store group iterator as a list\\n   uniquekeys.append(k)\\n\\n\\nk is the current grouping key, and g is an iterator that you can use to iterate over the group defined by that grouping key. In other words, the groupby iterator itself returns iterators.\\n\\nHere\\'s an example of that, using clearer variable names:\\n\\nfrom itertools import groupby\\n\\nthings = [(\"animal\", \"bear\"), (\"animal\", \"duck\"), (\"plant\", \"cactus\"), (\"vehicle\", \"speed boat\"), (\"vehicle\", \"school bus\")]\\n\\nfor key, group in groupby(things, lambda x: x[0]):\\n    for thing in group:\\n        print \"A %s is a %s.\" % (thing[1], key)\\n    print \" \"\\n\\n\\nThis will give you the output:\\n\\n\\n  A bear is a animal.\\n  A duck is a animal.\\n  \\n  A cactus is a plant.\\n  \\n  A speed boat is a vehicle.\\n  A school bus is a vehicle.\\n\\n\\nIn this example, things is a list of tuples where the first item in each tuple is the group the second item belongs to. \\n\\nThe groupby() function takes two arguments: (1) the data to group and (2) the function to group it with. \\n\\nHere, lambda x: x[0] tells groupby() to use the first item in each tuple as the grouping key.\\n\\nIn the above for statement, groupby returns three (key, group iterator) pairs - once for each unique key. You can use the returned iterator to iterate over each individual item in that group.\\n\\nHere\\'s a slightly different example with the same data, using a list comprehension:\\n\\nfor key, group in groupby(things, lambda x: x[0]):\\n    listOfThings = \" and \".join([thing[1] for thing in group])\\n    print key + \"s:  \" + listOfThings + \".\"\\n\\n\\nThis will give you the output:\\n\\n\\n  animals: bear and duck.\\n  plants: cactus.\\n  vehicles: speed boat and school bus.\\n\\n'}\n____________________________________________________________________________________________________ \n1. {'Question': \"Why is ''>0 True in Python?\", 'Answer': 'The original design motivation for allowing order-comparisons of arbitrary objects was to allow sorting of heterogenous lists -- usefully, that would put all strings next to each other in alphabetical order, and all numbers next to each other in numerical order, although which of the two blocks came first was not guaranteed by the language.  For example, this allowed getting only unique items in any list (even one with non-hashable items) in O(N log N) worst-case time\\n\\nOver the years, this pragmatical arrangement was eroded.  The first crack was when the ability to order-compare complex numbers was taken away, quite a few versions ago: suddenly, the ability to sort any list disappeared (did not apply any more if the list contained complex numbers, possibly together with items of other types).  Then Guido started disliking heterogeneous lists more generally, and thus thinking that it didn\\'t really matter if such lists could be usefully sorted or not... because such lists should not exist in the first place, according to his new thinking.  He didn\\'t do anything to forbid them, but was not inclined to accept any compromises to support them either.\\n\\nNote that both changes move the balance a little bit away from the \"practicality beats purity\" item of the Zen of Python (which was written earlier, back when complex numbers still could be order-compared;-) -- a bit more purity, a bit less practicality.\\n\\nNevertheless the ability to order-compare two arbitrary objects (as long as neither was a complex number;-) remained for a long time, because around that same time Guido started really insisting on maintaining strong backwards compatibility (a shift that\\'s both practical and pure;-).\\n\\nSo, it\\'s only in Python 3, which explicitly and deliberately removed the constraint of strong backwards compatibility to allow some long-desired but backwards incompatible enhancements (especially simplifications and removal of obsolete, redundant way to perform certain tasks), that order comparison of instances of different types became an error.\\n\\nSo this historical and philosophical treatise is basically the only way to truly respond to your \"why\" question...!-)\\n'}\n____________________________________________________________________________________________________ \n2. {'Question': 'How to check what OS am I running on in Python?', 'Answer': '&gt;&gt;&gt; import os\\n&gt;&gt;&gt; print os.name\\nposix\\n&gt;&gt;&gt; import platform\\n&gt;&gt;&gt; platform.system()\\n\\'Linux\\'\\n&gt;&gt;&gt; platform.release()\\n\\'2.6.22-15-generic\\'\\n\\n\\nSee: <a href=\"https://docs.python.org/2/library/platform.html\">platform Ã¢\\x80\\x94 Access to underlying platformÃ¢\\x80\\x99s identifying data\\n'}\n____________________________________________________________________________________________________ \n3. {'Question': 'Create an encrypted ZIP file in Python', 'Answer': 'I created a simple library to create a password encrypted zip file in python. - <a href=\"https://github.com/smihica/pyminizip\">here\\n\\nimport pyminizip\\n\\ncompression_level = 5 # 1-9\\npyminizip.compress(\"src.txt\", \"dst.zip\", \"password\", compression_level)\\n\\n\\nThe library requires zlib.\\n\\nI have checked that the file can be extracted in WINDOWS/MAC.\\n'}\n____________________________________________________________________________________________________ \n4. {'Question': 'Recursively walking a Python inheritance tree at run-time', 'Answer': 'You might try using the type.mro() method to find the method resolution order.\\n\\nclass A(object):\\n        pass\\n\\nclass B(A):\\n        pass\\n\\nclass C(A):\\n        pass\\n\\na = A()\\nb = B()\\nc = C()\\n\\n&gt;&gt;&gt; type.mro(type(b))\\n[&lt;class \\'__main__.B\\'&gt;, &lt;class \\'__main__.A\\'&gt;, &lt;type \\'object\\'&gt;]\\n&gt;&gt;&gt; type.mro(type(c))\\n[&lt;class \\'__main__.C\\'&gt;, &lt;class \\'__main__.A\\'&gt;, &lt;type \\'object\\'&gt;]\\n\\n\\nor\\n\\n&gt;&gt;&gt; type(b).mro()\\n\\n\\n\\n\\nEdit:  I was thinking you wanted to do something like this...\\n\\n&gt;&gt;&gt; A = type(\"A\", (object,), {\\'a\\':\\'A var\\'})  # create class A\\n&gt;&gt;&gt; B = type(\"B\", (A,), {\\'b\\':\\'B var\\'})       # create class B\\n&gt;&gt;&gt; myvar = B()\\n\\ndef getvars(obj):\\n    \\'\\'\\' return dict where key/value is attribute-name/class-name \\'\\'\\'\\n    retval = dict()\\n    for i in type(obj).mro():\\n        for k in i.__dict__:\\n            if not k.startswith(\\'_\\'):\\n                retval[k] = i.__name__\\n    return retval\\n\\n&gt;&gt;&gt; getvars(myvar)\\n{\\'a\\': \\'A\\', \\'b\\': \\'B\\'}\\n\\n&gt;&gt;&gt; for i in getvars(myvar):\\n    print getattr(myvar, i)   # or use setattr to modify the attribute value\\n\\nA Var\\nB Var\\n\\n'}\n____________________________________________________________________________________________________ \n5. {'Question': 'How can I retrieve the page title of a webpage using Python?', 'Answer': 'Here\\'s a simplified version of <a href=\"http://stackoverflow.com/a/51242/4279\">@Vinko Vrsalovic\\'s answer:\\n\\nimport urllib2\\nfrom BeautifulSoup import BeautifulSoup\\n\\nsoup = BeautifulSoup(urllib2.urlopen(\"https://www.google.com\"))\\nprint soup.title.string\\n\\n\\nNOTE:\\n\\n\\nsoup.title finds the first title element anywhere in the html document\\ntitle.string assumes it has only one child node, and that child node is a string\\n\\n\\nFor <a href=\"http://www.crummy.com/software/BeautifulSoup/bs4/doc/\">beautifulsoup 4.x, use different import:\\n\\nfrom bs4 import BeautifulSoup\\n\\n'}\n____________________________________________________________________________________________________ \n6. {'Question': 'In Python, how can you easily retrieve sorted items from a dictionary?', 'Answer': 'Or shorter,\\n\\nfor key, value in sorted(d.items()):\\n    print value\\n\\n'}\n____________________________________________________________________________________________________ \n7. {'Question': 'Python Inverse of a Matrix', 'Answer': 'You should have a look at <a href=\"http://www.scipy.org/Tentative_NumPy_Tutorial\">numpy if you do matrix manipulation. This is a module mainly written in C, which will be much faster than programming in pure python. Here is an example of how to invert a matrix, and do other matrix manipulation.\\n\\nfrom numpy import matrix\\nfrom numpy import linalg\\nA = matrix( [[1,2,3],[11,12,13],[21,22,23]]) # Creates a matrix.\\nx = matrix( [[1],[2],[3]] )                  # Creates a matrix (like a column vector).\\ny = matrix( [[1,2,3]] )                      # Creates a matrix (like a row vector).\\nprint A.T                                    # Transpose of A.\\nprint A*x                                    # Matrix multiplication of A and x.\\nprint A.I                                    # Inverse of A.\\nprint linalg.solve(A, x)     # Solve the linear equation system.\\n\\n\\nYou can also have a look at the <a href=\"http://www.python.org/doc/2.5.2/lib/module-array.html\">array module, which is a much more efficient implementation of lists when you have to deal with only one data type.\\n'}\n____________________________________________________________________________________________________ \n8. {'Question': 'How to integrate pep8.py in Eclipse?', 'Answer': 'As of PyDev 2.3.0, pep8 is integrated in PyDev by default, even shipping with a default version of it.\\n\\nOpen Window > Preferences\\n\\nIt must be enabled in PyDev > Editor > Code Analysis > pep8.py\\n\\nErrors/Warnings should be shown as markers (as other things in the regular code analysis).\\n\\nIn the event a file is not analyzed, see <a href=\"https://stackoverflow.com/a/31001619/832230\">https://stackoverflow.com/a/31001619/832230.\\n'}\n____________________________________________________________________________________________________ \n9. {'Question': 'How can I select all of the Sundays for a year using Python?', 'Answer': 'You can use date from the <a href=\"http://docs.python.org/library/datetime.html\">datetime module to find the first Sunday in a year and then keep adding seven days, generating new Sundays:\\n\\nfrom datetime import date, timedelta\\n\\ndef allsundays(year):\\n   d = date(year, 1, 1)                    # January 1st\\n   d += timedelta(days = 6 - d.weekday())  # First Sunday\\n   while d.year == year:\\n      yield d\\n      d += timedelta(days = 7)\\n\\nfor d in allsundays(2010):\\n   print d\\n\\n'}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG data"
      ],
      "metadata": {
        "id": "5Sj9f4bG7VEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "peps = Peps()\n",
        "peps_corpus = peps.scrape()\n",
        "print(\n",
        "    'corpus lenght:',\n",
        "    len(peps_corpus),\n",
        "    '\\nsection <n> lenght:',\n",
        "    len(peps_corpus[0]),\n",
        "    '\\nsample text:\\n\\n',\n",
        "    peps_corpus[10][1306:2000]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:39:55.567845Z",
          "iopub.execute_input": "2024-04-06T15:39:55.568132Z",
          "iopub.status.idle": "2024-04-06T15:44:22.809656Z",
          "shell.execute_reply.started": "2024-04-06T15:39:55.568109Z",
          "shell.execute_reply": "2024-04-06T15:44:22.80853Z"
        },
        "trusted": true,
        "id": "r-6sBQf07VEx",
        "outputId": "3b35f8cf-e519-4598-9e08-5869647454ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "corpus lenght: 644 \nsection <n> lenght: 61646 \nsample text:\n\n ementation\nRelated work\nAcknowledgements\nCopyright\n\n\n\nAttention\nThis PEP is a historical document. The up-to-date, canonical spec, Literals, is maintained on the typing specs site.\nÃ—\nSee the typing specification update process for how to propose changes.\n\n\nAbstract\nThis PEP proposes adding Literal types to the PEP 484 ecosystem.\nLiteral types indicate that some expression has literally a\nspecific value. For example, the following function will accept\nonly expressions that have literally the value â€œ4â€:\nfrom typing import Literal\n\ndef accepts_only_four(x: Literal[4]) -> None:\n    pass\n\naccepts_only_four(4)   # OK\naccepts_only_four(19)  # Rejected\n\n\n\n\nMotivation and Rationale\nPython has m\nCPU times: user 50.9 s, sys: 764 ms, total: 51.7 s\nWall time: 4min 27s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "peps = Peps()\n",
        "data = peps.jsonl_format()\n",
        "data[-1]['text'][:2000]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:44:22.810847Z",
          "iopub.execute_input": "2024-04-06T15:44:22.811148Z",
          "iopub.status.idle": "2024-04-06T15:45:45.549564Z",
          "shell.execute_reply.started": "2024-04-06T15:44:22.811121Z",
          "shell.execute_reply": "2024-04-06T15:45:45.548593Z"
        },
        "trusted": true,
        "id": "ebxV8gaA7VEx",
        "outputId": "f2aebf54-7da8-4c7a-9ef1-1dea4b683096"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "CPU times: user 53.7 s, sys: 698 ms, total: 54.4 s\nWall time: 1min 22s\n",
          "output_type": "stream"
        },
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\n\\nPython Enhancement Proposals\\n\\nPython Â» \\nPEP Index Â» \\nPEP 593\\n\\n\\n\\n\\n\\nToggle light / dark / auto colour theme\\n\\n\\n\\n\\nPEP 593 â€“ Flexible function and variable annotations\\n\\nAuthor:\\nTill Varoquaux <till at fb.com>, Konstantin Kashin <kkashin at fb.com>\\nSponsor:\\nIvan Levkivskyi <levkivskyi at gmail.com>\\nDiscussions-To:\\nTyping-SIG list\\nStatus:\\nFinal\\nType:\\nStandards Track\\nTopic:\\nTyping\\nCreated:\\n26-Apr-2019\\nPython-Version:\\n3.9\\nPost-History:\\n20-May-2019\\n\\n\\n\\nTable of Contents\\nAbstract\\nMotivation\\nRationale\\nMotivating examples\\nCombining runtime and static uses of annotations\\nLowering barriers to developing new typing constructs\\n\\n\\nSpecification\\nSyntax\\nConsuming annotations\\nInteraction with get_type_hints()\\nAliases & Concerns over verbosity\\n\\n\\nRejected ideas\\nCopyright\\n\\n\\n\\nAttention\\nThis PEP is a historical document. The up-to-date, canonical spec, Annotated, is maintained on the typing specs site.\\nÃ—\\nSee the typing specification update process for how to propose changes.\\n\\n\\nAbstract\\nThis PEP introduces a mechanism to extend the type annotations from PEP\\n484 with arbitrary metadata.\\n\\n\\nMotivation\\nPEP 484 provides a standard semantic for the annotations introduced in\\nPEP 3107. PEP 484 is prescriptive but it is the de facto standard\\nfor most of the consumers of annotations; in many statically checked\\ncode bases, where type annotations are widely used, they have\\neffectively crowded out any other form of annotation. Some of the use\\ncases for annotations described in PEP 3107 (database mapping,\\nforeign languages bridge) are not currently realistic given the\\nprevalence of type annotations. Furthermore, the standardisation of type\\nannotations rules out advanced features only supported by specific type\\ncheckers.\\n\\n\\nRationale\\nThis PEP adds an Annotated type to the typing module to decorate\\nexisting types with context-specific metadata. Specifically, a type\\nT can be annotated with metadata x via the typehint\\nAnnotated[T, x]. This metadata can be used for either static\\nanalysis or at runtime. If a libr'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG"
      ],
      "metadata": {
        "id": "DJvR58fcsoW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "embeder = Embeder()\n",
        "vec = embeder.run([\"hello I'm goku\"])[0]\n",
        "print(len(vec))\n",
        "vec[:10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T16:08:51.01968Z",
          "iopub.execute_input": "2024-04-06T16:08:51.020041Z",
          "iopub.status.idle": "2024-04-06T16:09:09.776656Z",
          "shell.execute_reply.started": "2024-04-06T16:08:51.020014Z",
          "shell.execute_reply": "2024-04-06T16:09:09.775756Z"
        },
        "trusted": true,
        "id": "j8gWCz2e7VEx",
        "outputId": "ba19c362-e37c-4b26-d090-c1b03f6b4ef2",
        "colab": {
          "referenced_widgets": [
            "e0fedd46c1b64ae88d01077f402e763b",
            "6f6261c8bc5e485bab385c73f0de2a97",
            "a4620da70bdb4bf1b71ea12090665047",
            "b59fc975f44247018c943e1759da7613",
            "7253c7fba78e4d4586adb37d2c74971f",
            "88997c0053874d7691d128d409f77a72",
            "ea03e6a5fffd409ea4d20ea67878f627",
            "fa07180ad3d24705871a668dd82cad9b",
            "b8480337280b40e2b463fa4c21f46753",
            "57caadc1a8334217b98ad9c4f649e53a"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0fedd46c1b64ae88d01077f402e763b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f6261c8bc5e485bab385c73f0de2a97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/4.12k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4620da70bdb4bf1b71ea12090665047"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b59fc975f44247018c943e1759da7613"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7253c7fba78e4d4586adb37d2c74971f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88997c0053874d7691d128d409f77a72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea03e6a5fffd409ea4d20ea67878f627"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa07180ad3d24705871a668dd82cad9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8480337280b40e2b463fa4c21f46753"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57caadc1a8334217b98ad9c4f649e53a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "384\nCPU times: user 3.18 s, sys: 1.11 s, total: 4.29 s\nWall time: 18.7 s\n",
          "output_type": "stream"
        },
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[-0.1933707594871521,\n 0.08631032705307007,\n 0.2352217584848404,\n 0.4100143313407898,\n -0.14344947040081024,\n 0.19855117797851562,\n 0.46806424856185913,\n -0.08672317862510681,\n -0.2187383770942688,\n 0.1548473834991455]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "retriever = Retriever()\n",
        "retriever.set(data[int(len(data)/2):])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T16:16:15.023481Z",
          "iopub.execute_input": "2024-04-06T16:16:15.023878Z",
          "iopub.status.idle": "2024-04-06T16:42:47.674947Z",
          "shell.execute_reply.started": "2024-04-06T16:16:15.023847Z",
          "shell.execute_reply": "2024-04-06T16:42:47.673935Z"
        },
        "trusted": true,
        "id": "_OfVDcnE7VE2",
        "outputId": "f5d3a597-8531-42b2-f106-097ca0832a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "CPU times: user 24min 34s, sys: 4min 34s, total: 29min 9s\nWall time: 26min 32s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al data/instruct-embeddings-public-crypto"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T16:53:28.840726Z",
          "iopub.execute_input": "2024-04-06T16:53:28.841698Z",
          "iopub.status.idle": "2024-04-06T16:53:29.921066Z",
          "shell.execute_reply.started": "2024-04-06T16:53:28.841644Z",
          "shell.execute_reply": "2024-04-06T16:53:29.919979Z"
        },
        "trusted": true,
        "id": "rXx76DXZ7VE2",
        "outputId": "f0fcceff-acb2-4613-8337-15fe8aca5096"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "total 4897712\ndrwxr-xr-x 4 root root       4096 Apr  6 16:42 .\ndrwxr-xr-x 3 root root       4096 Apr  6 15:34 ..\ndrwxr-xr-x 2 root root       4096 Apr  6 15:34 c0b29a2b-63aa-48ea-94fc-f29c2ea191b3\n-rw-r--r-- 1 root root        559 Apr  6 15:34 chroma-collections.parquet\n-rw-r--r-- 1 root root  265655481 Apr  6 15:34 chroma-embeddings.parquet\n-rw-r--r-- 1 root root 4749570048 Apr  6 16:42 chroma.sqlite3\ndrwxr-xr-x 2 root root       4096 Apr  6 15:34 index\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len('either the latest version of Python installed on the system, or')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T16:55:45.988923Z",
          "iopub.execute_input": "2024-04-06T16:55:45.989914Z",
          "iopub.status.idle": "2024-04-06T16:55:45.995795Z",
          "shell.execute_reply.started": "2024-04-06T16:55:45.989876Z",
          "shell.execute_reply": "2024-04-06T16:55:45.994782Z"
        },
        "trusted": true,
        "id": "UTcNL2Je7VE2",
        "outputId": "d212cf12-b653-4937-d1c3-c69d5e7d6d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 48,
          "output_type": "execute_result",
          "data": {
            "text/plain": "63"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = Retriever()\n",
        "question = \"\"\"\n",
        "Rationale\\nThis idea was proposed by Guido van Rossum on the python-ideas [1] mailing\\nlist. The premise of his email was to slow the alteration of the  Python core\\nsyntax, builtins and semantics to allow non-CPython implementations to catch\\nup to the current state of Python, both 2.x and 3.x.\\nPython, as a language is more than the core implementation â€“\\nCPython â€“ with a rich, mature and vibrant community of implementations, such\\nas Jython [2], IronPython [3] and PyPy [4] that are a benefit not only to\\nthe community, but to the language itself.\\nStill others, such as Unladen Swallow [5] (a branch of CPython) seek not to\\ncreate an alternative implementation, but rather they seek to enhance the\\nperformance and implementation of CPython itself.\\nPython 3.x was a large part of the last several years of Pythonâ€™s\\ndevelopment. Its release, as well as a bevy of changes to the language\\nintroduced by it and the previous 2.6.x releases, puts alternative\n",
        "\"\"\"\n",
        "retriever.query(question,\n",
        "            k=100,\n",
        "            threshold=11)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T16:55:54.262152Z",
          "iopub.execute_input": "2024-04-06T16:55:54.262758Z",
          "iopub.status.idle": "2024-04-06T16:55:57.860226Z",
          "shell.execute_reply.started": "2024-04-06T16:55:54.262727Z",
          "shell.execute_reply": "2024-04-06T16:55:57.859338Z"
        },
        "trusted": true,
        "id": "ZDL2bcrV7VE2",
        "outputId": "6233a23f-3d41-4789-86de-c08bb7ee54d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 49,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['Existing Approaches for Python\\n\\nmypy\\n(This section is a stub, since mypy is essentially what weâ€™re\\nproposing.)\\n\\n\\nReticulated Python\\nReticulated Python by Michael Vitousek is an example of\\na slightly different approach to gradual typing for Python. It is\\ndescribed in an actual academic paper written by\\nVitousek with Jeremy Siek and Jim Baker (the latter of Jython fame).\\n\\n\\nPyCharm\\nPyCharm by JetBrains has been providing a way to specify and check\\ntypes for about four years.  The type system suggested by PyCharm\\ngrew from simple class types to tuple types, generic types,\\nfunction types, etc. based on feedback of many users who shared their\\nexperience of using type hints in their code.\\n\\n\\nOthers\\nTBD: Add sections on pyflakes, pylint, numpy,\\nArgument Clinic, pytypedecl, numba, obiwan.\\n\\n\\n\\nExisting Approaches in Other Languages',\n 'Others\\nTBD: Add sections on pyflakes, pylint, numpy,\\nArgument Clinic, pytypedecl, numba, obiwan.\\n\\n\\n\\nmypy\\n(This section is a stub, since mypy is essentially what weâ€™re\\nproposing.)\\n\\n\\nReticulated Python\\nReticulated Python by Michael Vitousek is an example of\\na slightly different approach to gradual typing for Python. It is\\ndescribed in an actual academic paper written by\\nVitousek with Jeremy Siek and Jim Baker (the latter of Jython fame).\\n\\n\\nPyCharm\\nPyCharm by JetBrains has been providing a way to specify and check\\ntypes for about four years.  The type system suggested by PyCharm\\ngrew from simple class types to tuple types, generic types,\\nfunction types, etc. based on feedback of many users who shared their\\nexperience of using type hints in their code.\\n\\n\\nOthers\\nTBD: Add sections on pyflakes, pylint, numpy,\\nArgument Clinic, pytypedecl, numba, obiwan.\\n\\n\\nExisting Approaches in Other Languages',\n 'Rationale\\nThis proposal intends to address these shortcomings by extending and complementing the\\ninformation in docstrings, keeping backwards compatibility with existing docstrings\\n(it doesnâ€™t deprecate them), and doing it in a way that leverages the Python\\nlanguage and structure, via type annotations with Annotated, and\\na new class Doc in typing.\\nThe reason why this would belong in the standard Python library instead of an\\nexternal package is because although the implementation would be quite trivial,\\nthe actual power and benefit from it would come from being a standard, to facilitate\\nits usage from library authors and to provide a default way to document Python\\nsymbols using Annotated. Some tool providers (at least VS Code\\nand PyCharm) have shown they would consider implementing support for this only if\\nit was a standard.\\nThis doesnâ€™t deprecate current usage of docstrings, docstrings should be considered',\n 'Rationale\\nBack in the early days of Python, the interpreter came with a large set of\\nuseful modules. This was often referred to as â€œbatteries includedâ€\\nphilosophy and was one of the cornerstones to Pythonâ€™s success story.\\nUsers didnâ€™t have to figure out how to download and install separate\\npackages in order to write a simple web server or parse email.\\nTimes have changed. With the introduction of PyPI (nÃ©e Cheeseshop), setuptools,\\nand later pip, it became simple and straightforward to download and install\\npackages. Nowadays Python has a rich and vibrant ecosystem of third-party\\npackages. Itâ€™s pretty much standard to either install packages from PyPI or\\nuse one of the many Python or Linux distributions.\\nOn the other hand, Pythonâ€™s standard library is piling up with cruft, unnecessary\\nduplication of functionality, and dispensable features. This is undesirable\\nfor several reasons.',\n 'PyPy\\nSome of the PyPy developers have responded to a request for feedback\\n[9].  Armin Rigo said the following [10]:\\nFor myself, I can only say that it looks like a good idea, which we\\nwill happily adhere to when we migrate to Python 3.3.\\n\\n\\nHe also expressed support for keeping the required list small.  Both\\nArmin and Laura Creighton indicated that an effort to better catalog\\nPythonâ€™s implementation would be welcome.  Such an effort, for which\\nthis PEP is a small start, will be considered separately.\\n\\n\\nPast Efforts\\n\\nPEP 3139\\nPEP 3139, from 2008, recommended a clean-up of the sys module in\\npart by extracting implementation-specific variables and functions\\ninto a separate module.  PEP 421 is less ambitious version of that\\nidea.  While PEP 3139 was rejected, its goals are reflected in PEP 421\\nto a large extent, though with a much lighter approach.',\n 'And generally:\\n\\nIs consistent with iterator-based â€œconvenienceâ€ changes already\\nincluded (as of Python 2.1) for other builtin types such as:\\nlists, tuples, dictionaries, strings, and files.\\n\\n\\n\\nBackwards Compatibility\\nThe proposed mechanism is generally backwards compatible as it\\ncalls for neither new syntax nor new keywords.  All existing,\\nvalid Python programs should continue to work unmodified.\\nHowever, this proposal is not perfectly backwards compatible in\\nthe sense that certain statements that are currently invalid\\nwould, under the current proposal, become valid.\\nTim Peters has pointed out two such examples:\\n\\nThe common case where one forgets to include range() or\\nxrange(), for example:for rowcount in table.getRowCount():\\n    print table.getValueAt(rowcount, 0)',\n 'Rationale\\nSo far, we have 4 major Python implementations â€“ CPython, Jython,\\nIronPython, and PyPy â€“ as well as lots of minor ones.  Some of\\nthese already run on platforms that do aggressive optimizations.  In\\ngeneral, these optimizations are invisible within a single thread of\\nexecution, but they can be visible to other threads executing\\nconcurrently.  CPython currently uses a GIL to ensure that other\\nthreads see the results they expect, but this limits it to a single\\nprocessor.  Jython and IronPython run on Javaâ€™s or .NETâ€™s threading\\nsystem respectively, which allows them to take advantage of more cores\\nbut can also show surprising values to other threads.\\nSo that threaded Python programs continue to be portable between\\nimplementations, implementers and library authors need to agree on\\nsome ground rules.\\n\\n\\nA couple definitions',\n 'Motivation\\nFor a number of years now, the distinction between Python-the-language\\nand CPython (the reference implementation) has been growing.  Most of\\nthis change is due to the emergence of Jython, IronPython, and PyPy as\\nviable alternate implementations of Python.\\nConsider, however, the nearly two decades of CPython-centric Python\\n(i.e. most of its existence).  That focus has understandably\\ncontributed to quite a few CPython-specific artifacts both in the\\nstandard library and exposed in the interpreter.  Though the core\\ndevelopers have made an effort in recent years to address this, quite\\na few of the artifacts remain.\\nPart of the solution is presented in this PEP: a single namespace in\\nwhich to consolidate implementation specifics.  This will help focus\\nefforts to differentiate the implementation specifics from the\\nlanguage.  Additionally, it will foster a multiple-implementation\\nmindset.',\n 'Rationale\\nThere are two current approaches to bringing co-routines to Python.\\nChristian Tismerâ€™s Stackless [6] involves a ground-up restructuring\\nof Pythonâ€™s execution model by hacking the â€˜Câ€™ stack.  While this\\napproach works, its operation is hard to describe and keep portable. A\\nrelated approach is to compile Python code to Parrot [7], a\\nregister-based virtual machine, which has coroutines.  Unfortunately,\\nneither of these solutions is portable with IronPython (CLR) or Jython\\n(JavaVM).\\nIt is thought that a more limited approach, based on iterators, could\\nprovide a coroutine facility to application programmers and still be\\nportable across runtimes.',\n 'Rationale\\nPython has grown beyond the CPython virtual machine (VM). IronPython,\\nJython, and PyPy are all currently viable alternatives to the\\nCPython VM. The VM ecosystem that has sprung up around the Python\\nprogramming language has led to Python being used in many different\\nareas where CPython cannot be used, e.g., Jython allowing Python to be\\nused in Java applications.\\nA problem all of the VMs other than CPython face is handling modules\\nfrom the standard library that are implemented (to some extent) in C.\\nSince other VMs do not typically support the entire C API of CPython\\nthey are unable to use the code used to create the module. Oftentimes\\nthis leads these other VMs to either re-implement the modules in pure\\nPython or in the programming language used to implement the VM itself\\n(e.g., in C# for IronPython). This duplication of effort between\\nCPython, PyPy, Jython, and IronPython is extremely unfortunate as\\nimplementing a module at least in pure Python would help mitigate',\n 'Rationale\\nOne place where flexibility has been lacking in Python is in the direct\\nexecution of Python code. While CPythonâ€™s C API [2] allows for\\nconstructing the data going into a frame object and then evaluating it\\nvia PyEval_EvalFrameEx() [5], control over the\\nexecution of Python code comes down to individual objects instead of a\\nholistic control of execution at the frame level.\\nWhile wanting to have influence over frame evaluation may seem a bit\\ntoo low-level, it does open the possibility for things such as a\\nmethod-level JIT to be introduced into CPython without CPython itself\\nhaving to provide one. By allowing external C code to control frame\\nevaluation, a JIT can participate in the execution of Python code at\\nthe key point where evaluation occurs. This then allows for a JIT to\\nconditionally recompile Python bytecode to machine code as desired\\nwhile still allowing for executing regular CPython bytecode when\\nrunning the JIT is not desired. This can be accomplished by allowing',\n 'Rationale\\nThis idea was proposed by Guido van Rossum on the python-ideas [1] mailing\\nlist. The premise of his email was to slow the alteration of the  Python core\\nsyntax, builtins and semantics to allow non-CPython implementations to catch\\nup to the current state of Python, both 2.x and 3.x.\\nPython, as a language is more than the core implementation â€“\\nCPython â€“ with a rich, mature and vibrant community of implementations, such\\nas Jython [2], IronPython [3] and PyPy [4] that are a benefit not only to\\nthe community, but to the language itself.\\nStill others, such as Unladen Swallow [5] (a branch of CPython) seek not to\\ncreate an alternative implementation, but rather they seek to enhance the\\nperformance and implementation of CPython itself.\\nPython 3.x was a large part of the last several years of Pythonâ€™s\\ndevelopment. Its release, as well as a bevy of changes to the language\\nintroduced by it and the previous 2.6.x releases, puts alternative',\n 'As will be noted below, there are ways to work around this at the\\nexpense of increased complication.  Ultimately the simplest approach is\\nthe one that makes the most sense: pack collected key word arguments\\ninto an OrderedDict.  However, without a C implementation of OrderedDict\\nthere isnâ€™t much to discuss.  That changed in Python 3.5.\\n[10]\\nNote: in Python 3.6 dict is order-preserving.  This virtually eliminates\\nperformance concerns.\\n\\n\\nOther Python Implementations\\nAnother important issue to consider is that new features must be\\ncognizant of the multiple Python implementations.  At some point each of\\nthem would be expected to have implemented ordered kwargs.  In this\\nregard there doesnâ€™t seem to be an issue with the idea. [11]\\nAn informal survey of the major Python implementations has indicated\\nthat this feature will not be a significant burden.',\n '[8] (1, 2) \\nThe Python string formatting syntax.\\n(https://docs.python.org/3.1/library/string.html#format-string-syntax)\\n\\n\\n\\nCopyright\\nThis document has been placed in the public domain.\\n\\n\\n\\nTable of Contents\\nAbstract\\nPEP Rejection\\nMotivation\\nSpecification\\nOverview\\npypa.json\\nProcess interface\\nAvailable format variables\\nAvailable environment variables\\nSubcommands\\nThe build environment\\nHermetic builds\\nUpgrades\\nStatic metadata in sdists\\nHandling of compiler options\\n\\n\\nExamples\\nBackwards Compatibility\\nNetwork effects\\nsetuptools shim\\n\\n\\nRationale\\nReferences\\nCopyright\\n\\n\\n\\nAbstract\\nThis PEP specifies a programmatic interface for pip [1] and other\\ndistribution or installation tools to use when working with Python\\nsource trees (both the developer tree - e.g. the git tree - and source\\ndistributions).\\nThe programmatic interface allows decoupling of pip from its current\\nhard dependency on setuptools [2] able for two\\nkey reasons:']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len('Rationale\\nThis idea was proposed by Guido van Rossum on the python-ideas [1] mailing\\nlist. The premise of his email was to slow the alteration of the  Python core\\nsyntax, builtins and semantics to allow non-CPython implementations to catch\\nup to the current state of Python, both 2.x and 3.x.\\nPython, as a language is more than the core implementation â€“\\nCPython â€“ with a rich, mature and vibrant community of implementations, such\\nas Jython [2], IronPython [3] and PyPy [4] that are a benefit not only to\\nthe community, but to the language itself.\\nStill others, such as Unladen Swallow [5] (a branch of CPython) seek not to\\ncreate an alternative implementation, but rather they seek to enhance the\\nperformance and implementation of CPython itself.\\nPython 3.x was a large part of the last several years of Pythonâ€™s\\ndevelopment. Its release, as well as a bevy of changes to the language\\nintroduced by it and the previous 2.6.x releases, puts alternative')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T16:49:49.986098Z",
          "iopub.execute_input": "2024-04-06T16:49:49.98675Z",
          "iopub.status.idle": "2024-04-06T16:49:49.9934Z",
          "shell.execute_reply.started": "2024-04-06T16:49:49.986711Z",
          "shell.execute_reply": "2024-04-06T16:49:49.992486Z"
        },
        "trusted": true,
        "id": "szLiy1lz7VE2",
        "outputId": "1c9e4574-4a6c-45a6-d835-9b39d0a5126a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "951"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = Retriever()\n",
        "question = \"\"\"\n",
        "Rationale\\nThis idea was proposed by Guido van Rossum on the python-ideas [1] mailing\\nlist. The premise of his email was to slow the alteration of the  Python core\\nsyntax, builtins and semantics to allow non-CPython implementations to catch\\nup to the current state of Python, both 2.x and 3.x.\\nPython, as a language is more than the core implementation â€“\\nCPython â€“ with a rich, mature and vibrant community of implementations, such\\nas Jython [2], IronPython [3] and PyPy [4] that are a benefit not only to\\nthe community, but to the language itself.\\nStill others, such as Unladen Swallow [5] (a branch of CPython) seek not to\\ncreate an alternative implementation, but rather they seek to enhance the\\nperformance and implementation of CPython itself.\\nPython 3.x was a large part of the last several years of Pythonâ€™s\\ndevelopment. Its release, as well as a bevy of changes to the language\\nintroduced by it and the previous 2.6.x releases, puts alternative\n",
        "\"\"\"\n",
        "retriever.query(question)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T16:49:05.307873Z",
          "iopub.execute_input": "2024-04-06T16:49:05.308479Z",
          "iopub.status.idle": "2024-04-06T16:49:08.585342Z",
          "shell.execute_reply.started": "2024-04-06T16:49:05.308446Z",
          "shell.execute_reply": "2024-04-06T16:49:08.584374Z"
        },
        "trusted": true,
        "id": "sAwq5dDe7VE2",
        "outputId": "46c113e3-1c61-4041-a228-99fa8c9174ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['Rationale\\nThis idea was proposed by Guido van Rossum on the python-ideas [1] mailing\\nlist. The premise of his email was to slow the alteration of the  Python core\\nsyntax, builtins and semantics to allow non-CPython implementations to catch\\nup to the current state of Python, both 2.x and 3.x.\\nPython, as a language is more than the core implementation â€“\\nCPython â€“ with a rich, mature and vibrant community of implementations, such\\nas Jython [2], IronPython [3] and PyPy [4] that are a benefit not only to\\nthe community, but to the language itself.\\nStill others, such as Unladen Swallow [5] (a branch of CPython) seek not to\\ncreate an alternative implementation, but rather they seek to enhance the\\nperformance and implementation of CPython itself.\\nPython 3.x was a large part of the last several years of Pythonâ€™s\\ndevelopment. Its release, as well as a bevy of changes to the language\\nintroduced by it and the previous 2.6.x releases, puts alternative']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot"
      ],
      "metadata": {
        "id": "R3xhjyW9soW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading few-shot to the memory"
      ],
      "metadata": {
        "id": "BJcB53AU7VE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'data/history.json'\n",
        "message = Message(\n",
        "    role='sistem',\n",
        "    content='foo'\n",
        ")\n",
        "init_chat = [message.system_reply()]\n",
        "json.dump(init_chat, open(file, 'w'))\n",
        "for i, q in enumerate(few_shot_list):\n",
        "    sample = python_qa[q]\n",
        "    mesage = Message(\n",
        "        role='user',\n",
        "        content=sample['Question']\n",
        "    )\n",
        "    reply = mesage.update()\n",
        "    mesage = Message(\n",
        "        role='assitant',\n",
        "        content=sample['Answer']\n",
        "    )\n",
        "    reply = mesage.update()\n",
        "\n",
        "history = json.load(open(file))\n",
        "history"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-04-06T15:46:19.759106Z",
          "iopub.status.idle": "2024-04-06T15:46:19.759577Z",
          "shell.execute_reply.started": "2024-04-06T15:46:19.759327Z",
          "shell.execute_reply": "2024-04-06T15:46:19.759345Z"
        },
        "trusted": true,
        "id": "44de2MuD7VE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the RAG system memory"
      ],
      "metadata": {
        "id": "Sso2t2h17VE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent()\n",
        "print(agent.memory(\"\"\"\n",
        "Version Control System\n",
        "Currently the CPython and supporting repositories use Mercurial. As a modern distributed version control system, it has served us well since the migration from Subversion. However, when evaluating the VCS we must consider the capabilities of the VCS itself as well as the network effect and mindshare of the community around that VCS.\n",
        "\n",
        "There are really only two real options for this, Mercurial and Git. The technical capabilities of the two systems are largely equivalent, therefore this PEP instead focuses on their social aspects.\n",
        "\n",
        "It is not possible to get exact numbers for the number of projects or people which are using a particular VCS, however we can infer this by looking at several sources of information for what VCS projects are using.\n",
        "\n",
        "The Open Hub (previously Ohloh) statistics [1] show that 37% of the repositories indexed by The Open Hub are using Git (second only to Subversion which has 48%) while Mercurial has just 2%,\n",
        "\"\"\"))"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-04-06T15:46:19.760905Z",
          "iopub.status.idle": "2024-04-06T15:46:19.761341Z",
          "shell.execute_reply.started": "2024-04-06T15:46:19.761115Z",
          "shell.execute_reply": "2024-04-06T15:46:19.761134Z"
        },
        "trusted": true,
        "id": "3Q9_ZVn77VE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPC - 0.0.1"
      ],
      "metadata": {
        "id": "Cc_e_HAgsoW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:46:19.762864Z",
          "iopub.status.idle": "2024-04-06T15:46:19.763293Z",
          "shell.execute_reply.started": "2024-04-06T15:46:19.763071Z",
          "shell.execute_reply": "2024-04-06T15:46:19.763088Z"
        },
        "trusted": true,
        "id": "VWWjV41Z7VE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "agent = Agent()\n",
        "question = 'what is the latest python version that is currently lunched'\n",
        "print('*'*500,'\\n final answer:',agent.chat(question, verbose=True))"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-04-06T15:46:19.764472Z",
          "iopub.status.idle": "2024-04-06T15:46:19.764928Z",
          "shell.execute_reply.started": "2024-04-06T15:46:19.764705Z",
          "shell.execute_reply": "2024-04-06T15:46:19.764724Z"
        },
        "trusted": true,
        "id": "XJ0W5IL57VE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "agent = Agent()\n",
        "print(agent.chat('what is python??'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:46:19.766418Z",
          "iopub.status.idle": "2024-04-06T15:46:19.766898Z",
          "shell.execute_reply.started": "2024-04-06T15:46:19.766648Z",
          "shell.execute_reply": "2024-04-06T15:46:19.766667Z"
        },
        "trusted": true,
        "id": "4h5fSwqw7VE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_list=\"\"\"\n",
        "Python is a programming language. It is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\n",
        "Python is a general-purpose, high-level, interpreted, object-oriented, and extensible language. It is used for web development, scripting, and system administration.\n",
        "\"\"\".split('\\n')\n",
        "pos_list =  list(set(answer_list))\n",
        "pos_list"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:46:19.768778Z",
          "iopub.status.idle": "2024-04-06T15:46:19.769217Z",
          "shell.execute_reply.started": "2024-04-06T15:46:19.768986Z",
          "shell.execute_reply": "2024-04-06T15:46:19.769004Z"
        },
        "trusted": true,
        "id": "BOOPOt9G7VE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:46:19.770413Z",
          "iopub.status.idle": "2024-04-06T15:46:19.770867Z",
          "shell.execute_reply.started": "2024-04-06T15:46:19.770628Z",
          "shell.execute_reply": "2024-04-06T15:46:19.770645Z"
        },
        "trusted": true,
        "id": "rzL0Ff2l7VE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "agent = Agent()\n",
        "print(agent.chat('my name is juan nice to meet you!!!'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:46:19.772299Z",
          "iopub.status.idle": "2024-04-06T15:46:19.772759Z",
          "shell.execute_reply.started": "2024-04-06T15:46:19.772506Z",
          "shell.execute_reply": "2024-04-06T15:46:19.772525Z"
        },
        "trusted": true,
        "id": "xQZV6_yj7VE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = json.load(open(file))\n",
        "history"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:46:19.773951Z",
          "iopub.status.idle": "2024-04-06T15:46:19.774406Z",
          "shell.execute_reply.started": "2024-04-06T15:46:19.774169Z",
          "shell.execute_reply": "2024-04-06T15:46:19.774189Z"
        },
        "trusted": true,
        "id": "XKLF4-Wh7VE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tunning"
      ],
      "metadata": {
        "id": "5Jl33mfjsoW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPC - 0.1.0"
      ],
      "metadata": {
        "id": "xUdtzcyTsoW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(100000000000000000):\n",
        "#    1*1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-06T15:46:19.775944Z",
          "iopub.status.idle": "2024-04-06T15:46:19.776276Z",
          "shell.execute_reply.started": "2024-04-06T15:46:19.776113Z",
          "shell.execute_reply": "2024-04-06T15:46:19.776126Z"
        },
        "trusted": true,
        "id": "Zz8c6P197VE4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}